{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask_image.npy',\n",
       " 'mask_text.npy',\n",
       " 'mask_video.npy',\n",
       " 'mask_follow.npy',\n",
       " 'mask_social.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_ls = os.listdir('./npy/mask1ft/')\n",
    "ft_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFt(PATH):\n",
    "    return np.load(PATH)\n",
    "\n",
    "# Normalize usr_genre\n",
    "def ugNorm(usr_genre):\n",
    "    usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "    for i in range(len(usr_genre)):\n",
    "        usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "    print(usr_genre_norm.shape)\n",
    "    return usr_genre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(usr_following):\n",
    "    #The number of following movie for each user\n",
    "    each_user = np.sum(usr_following, axis=1)\n",
    "    # print(each_user)\n",
    "\n",
    "    print('Min number of followings:', np.min(each_user))\n",
    "    print('Max number of followings:', np.max(each_user))\n",
    "    print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "    asc = np.sort(each_user)\n",
    "    # print(each_user)\n",
    "    # print(asc)\n",
    "    desc = np.flip(asc)\n",
    "    # print(desc)\n",
    "    \n",
    "    print('Over 10:', np.sum(each_user >= 10))\n",
    "    print('Over 12:', np.sum(each_user >= 12))\n",
    "    print('Over 14:', np.sum(each_user >= 14))\n",
    "    print('Over 16:', np.sum(each_user >= 16))\n",
    "    print('Over 18:', np.sum(each_user >= 18))\n",
    "    print('Over 20:', np.sum(each_user >= 20))\n",
    "    \n",
    "    usr_idx = [i for i in range(len(usr_following))]\n",
    "    print(len(usr_idx))\n",
    "\n",
    "    random.seed(42)\n",
    "    test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "    print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n",
    "\n",
    "    # init\n",
    "    train_t = []\n",
    "    train_f = []\n",
    "    test_t = []\n",
    "    test_f = []\n",
    "\n",
    "    for i in range(usr_nb):\n",
    "        # init\n",
    "        t_for_train = []\n",
    "        f_for_train = []\n",
    "        t_for_test = []\n",
    "        f_for_test = []\n",
    "\n",
    "        if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "            for j in range(movie_nb):\n",
    "                if usr_following[i][j] == 1:\n",
    "                    t_for_train.append(j)\n",
    "                else:\n",
    "                    f_for_train.append(j)\n",
    "\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "    #         print(len(t_for_train) + len(f_for_train))\n",
    "\n",
    "        else: #if in test id, choose half of true and other \n",
    "            temp_t = []\n",
    "            temp_f = []\n",
    "\n",
    "            for j in range(movie_nb):\n",
    "                if usr_following[i][j] == 1:\n",
    "                    temp_t.append(j)\n",
    "                else:\n",
    "                    temp_f.append(j)\n",
    "\n",
    "            # random choose half true and half false for test \n",
    "            t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "            f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "\n",
    "            test_t.append(t_for_test)\n",
    "            test_f.append(f_for_test)\n",
    "\n",
    "            #the others for training\n",
    "            t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "            f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "\n",
    "        if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "    \n",
    "    return train_t, train_f, test_t, test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n",
      "1582 165\n",
      "150 32\n",
      "(1582, 20)\n",
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n",
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n",
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n",
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "# Basic setup\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)\n",
    "\n",
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "usr_genre_norm = ugNorm(usr_genre)\n",
    "train_t, train_f, test_t, test_f = train_test_split(usr_following)\n",
    "\n",
    "# Stat\n",
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)\n",
    "\n",
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_nb):\n",
    "            writeProgress('Progress:', z, usr_nb)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1=np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/mask1ft/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_image.npy\n",
      "All features: (165, 324)\n",
      "64 324 260\n",
      "SAVE_NAME: mask_image\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-10-5eb1d466eb10>:153: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "mask_image\n",
      "Start time: Mon Mar 30 11:37:30 2020\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [1582,165,260] and type float\n\t [[node item_level/Wv/Adam_1/Initializer/zeros (defined at <ipython-input-10-5eb1d466eb10>:152) ]]\n\nCaused by op 'item_level/Wv/Adam_1/Initializer/zeros', defined at:\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-5eb1d466eb10>\", line 152, in <module>\n    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1153, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1503, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 883, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 110, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1817, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3367, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [1582,165,260] and type float\n\t [[node item_level/Wv/Adam_1/Initializer/zeros (defined at <ipython-input-10-5eb1d466eb10>:152) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [1582,165,260] and type float\n\t [[{{node item_level/Wv/Adam_1/Initializer/zeros}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5eb1d466eb10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxuij\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mloss_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3eb4615846a0>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(SAVE_NAME)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [1582,165,260] and type float\n\t [[node item_level/Wv/Adam_1/Initializer/zeros (defined at <ipython-input-10-5eb1d466eb10>:152) ]]\n\nCaused by op 'item_level/Wv/Adam_1/Initializer/zeros', defined at:\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-5eb1d466eb10>\", line 152, in <module>\n    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 413, in minimize\n    name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 1153, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 183, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 157, in create_slot_with_initializer\n    dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1503, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 883, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 110, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1817, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3367, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [1582,165,260] and type float\n\t [[node item_level/Wv/Adam_1/Initializer/zeros (defined at <ipython-input-10-5eb1d466eb10>:152) ]]\n"
     ]
    }
   ],
   "source": [
    "for ft in ft_ls:\n",
    "    print(ft)\n",
    "    PATH = './npy/mask1ft/' + ft\n",
    "    all_npy = loadFt(PATH)\n",
    "    print('All features:', all_npy.shape)\n",
    "    \n",
    "    latent_dim = 64 # latent dims\n",
    "    ft_dim = all_npy.shape[1] # feature dims\n",
    "    embedding_dims = 260\n",
    "    print(latent_dim, ft_dim, embedding_dims)\n",
    "    \n",
    "    SAVE_NAME = ft.split('.')[0]\n",
    "    print('SAVE_NAME:', SAVE_NAME)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
