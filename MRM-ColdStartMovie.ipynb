{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 260\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split\n",
    "## Prepare\n",
    "### Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('<= 10:', np.sum(moive_followers <= 10))\n",
    "print('<= 15:', np.sum(moive_followers <= 15))\n",
    "print('<= 20:', np.sum(moive_followers <= 20))\n",
    "print('<= 25:', np.sum(moive_followers <= 25))\n",
    "print('<= 30:', np.sum(moive_followers <= 30))\n",
    "print('<= 35:', np.sum(moive_followers <= 35))\n",
    "print('<= 40:', np.sum(moive_followers <= 40))\n",
    "print('<= 45:', np.sum(moive_followers <= 45))\n",
    "print('<= 50:', np.sum(moive_followers <= 50))\n",
    "less_idx = np.nonzero(moive_followers <= 30)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(usr_following.shape)\n",
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = set()\n",
    "for idx in less_idx:\n",
    "    print('Index:', idx)\n",
    "    print('Sum:', usr_following[idx].sum())\n",
    "    print(usr_following[idx])\n",
    "    li = list(np.where(usr_following[idx] == 1)[0])\n",
    "    print(li)\n",
    "    st = st | set(li)\n",
    "    print(len(st), st)\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_idx = list(st)\n",
    "test_idx.sort()\n",
    "print(len(test_idx), test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = len(less_idx)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in test_idx:\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    temp_t = []\n",
    "    temp_f = []\n",
    "    for j in less_idx:\n",
    "        if usr_following[i][j] == 1:\n",
    "            temp_t.append(j)\n",
    "        else:\n",
    "            temp_f.append(j)\n",
    "            \n",
    "    t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "    f_for_test = random.sample(temp_f, math.ceil(0.5*len(temp_f)))\n",
    "    \n",
    "    test_t.append(t_for_test)\n",
    "    test_f.append(f_for_test)\n",
    "    \n",
    "    t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "    f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "    train_t.append(t_for_train)\n",
    "    train_f.append(f_for_train)\n",
    "    \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_test_amount:\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_test_amount\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allSortPrepare(testRS):\n",
    "    all_sort = []\n",
    "\n",
    "    for i in range(usr_test_amount):\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "\n",
    "    all_sort = np.asarray(all_sort)\n",
    "    print(all_sort.shape)\n",
    "    return all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg, all_sort): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testRS, target, sumtarget, all_sort):\n",
    "    print('\\n==============================\\n')\n",
    "    # Top N\n",
    "    N = [1, 5]\n",
    "    correct = 0\n",
    "\n",
    "    for n in N:\n",
    "        print('Top', n)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(testRS)):\n",
    "            topn = topN(testRS[i], n)\n",
    "            sum_target = int(np.sum(target[i]))\n",
    "\n",
    "            TP = 0\n",
    "            for i in topn:\n",
    "                if i < sum_target:\n",
    "                    TP += 1\n",
    "\n",
    "            correct += TP\n",
    "\n",
    "        prec = correct/(len(testRS)*n) #150*n\n",
    "        recall = correct/sumtarget\n",
    "\n",
    "        print('prec:', prec)\n",
    "        print('recall:', recall)\n",
    "        print('F1_score:', F1_score(prec, recall))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # NDCG\n",
    "    num_ndcgs = [10]\n",
    "    for num_ndcg in num_ndcgs:\n",
    "        print('NDCG@', num_ndcg)\n",
    "        print('NDCG score:', NDCG(target, testRS, num_ndcg, all_sort))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # MAP\n",
    "    print('MAP:', MAP(target,testRS))\n",
    "    print('\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "usr_test_amount = 147\n",
    "movie_test_amount = 13\n",
    "'''\n",
    "def testing(U, Y, A, E, Au, Ay, Aa, Av, B):\n",
    "    #with Embedding\n",
    "    result = np.zeros((usr_test_amount, movie_nb))\n",
    "    RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "    #test_idx --> Test 的 index length = 150\n",
    "    sum_alpha = 0\n",
    "    test_yes_id = []\n",
    "\n",
    "    for s in range(usr_test_amount):\n",
    "#         print(s, test_idx[s])\n",
    "\n",
    "        yes = []\n",
    "        sample = train_t[test_idx[s]]\n",
    "        alpha = np.zeros([len(sample)])\n",
    "\n",
    "        for a in range(len(sample)):\n",
    "            r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "\n",
    "    # #         ''' Observe each part in attention\n",
    "    #         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "    #         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "    #         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "    #         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "    #         print('The sum of each par -->',\n",
    "    #               '\\nw1:',testW1,\n",
    "    #               '\\nWuU:',WuUu,\n",
    "    #               '\\nwyY:',WyYy,\n",
    "    #               '\\nWaA:',WaAa,\n",
    "    #               '\\nWvV:',WvVy)\n",
    "    # #         '''\n",
    "\n",
    "            alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n",
    "                       np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                       np.dot(Aa[test_idx[s]][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                       np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "\n",
    "\n",
    "            # relu part\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            # tanh part\n",
    "    #         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "\n",
    "        mul = np.zeros((1,latent_dim))\n",
    "        added_alpha = np.add(alpha,0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "\n",
    "#         print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "#         print('==================================================')\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "        new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "\n",
    "        for k in range(movie_nb):\n",
    "            result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "    #取出test的資料\n",
    "    print(RS.shape)\n",
    "\n",
    "    testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "    target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "\n",
    "    for z in range(usr_test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        # positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        # not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "#         print(user_id)\n",
    "#         print(youtube_t)\n",
    "#         print(youtube_f)\n",
    "\n",
    "        #前面放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "\n",
    "    #     print(testRS[z])\n",
    "    #     print(target[z])\n",
    "    #     print('==============================')\n",
    "\n",
    "    print(target.shape, testRS.shape)\n",
    "    sumtarget = np.sum(target)\n",
    "    print('num of positive data in testing:', sumtarget) # whole matrix: 4800\n",
    "\n",
    "    # for metrics\n",
    "    metrics(testRS, target, sumtarget, allSortPrepare(testRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzs = ['MRM_E240_11.npz']\n",
    "npzs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for SAVE_NAME in npzs:\n",
    "    print(SAVE_NAME)\n",
    "    \n",
    "    params = np.load('./weight/grid/' + SAVE_NAME)\n",
    "#     print(params)\n",
    "    U = params['U']\n",
    "    Y = params['Y']\n",
    "    A = params['A']\n",
    "    E = params['E']\n",
    "    Au = params['Wu']\n",
    "    Ay = params['Wy']\n",
    "    Aa = params['Wa']\n",
    "    Av = params['Wv']\n",
    "    B = params['B']\n",
    "\n",
    "#     print('User latent shape: ',U.shape)\n",
    "#     print('photo latent shape: ', Y.shape)\n",
    "#     print('Auxilary latent shape: ',A.shape)\n",
    "#     print('Embedding shape:', E.shape)\n",
    "#     print('Wu weight shape:', Au.shape)\n",
    "#     print('Wy weight shape:', Ay.shape)\n",
    "#     print('Wa weight shape:', Aa.shape)\n",
    "#     print('Wv weight shape:', Av.shape)\n",
    "#     print('Beta shape:',B.shape)\n",
    "\n",
    "    testing(U, Y, A, E, Au, Ay, Aa, Av, B)\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
