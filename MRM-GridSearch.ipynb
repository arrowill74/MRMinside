{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2834)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2834.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "150 32\n",
      "64 2834\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "print(latent_dim, ft_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50: 125\n",
      "Over 100: 89\n",
      "Over 150: 58\n",
      "Over 200: 42\n",
      "Over 250: 31\n",
      "Over 300: 21\n"
     ]
    }
   ],
   "source": [
    "print('Over 50:', np.sum(moive_followers >= 50))\n",
    "print('Over 100:', np.sum(moive_followers >= 100))\n",
    "print('Over 150:', np.sum(moive_followers >= 150))\n",
    "print('Over 200:', np.sum(moive_followers >= 200))\n",
    "print('Over 250:', np.sum(moive_followers >= 250))\n",
    "print('Over 300:', np.sum(moive_followers >= 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) [  0   2   3   4   9  12  24  28  30  34  40  44  49  55  57  58  60  66\n",
      "  68  78  80  81  84  86  87  99 101 102 112 119 122 123 125 126 127 128\n",
      " 129 134 144 156 161 164]\n",
      "32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]\n"
     ]
    }
   ],
   "source": [
    "over200_idx = np.nonzero(moive_followers >= 200)[0]\n",
    "print(over200_idx.shape, over200_idx)\n",
    "\n",
    "random.seed(42)\n",
    "movie_test_idx = sorted(random.sample(list(over200_idx), movie_test_amount))\n",
    "print(len(movie_test_idx), movie_test_idx) # 32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(usr_following, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "asc = np.sort(each_user)\n",
    "# print(each_user)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n"
     ]
    }
   ],
   "source": [
    "print('Over 10:', np.sum(each_user >= 10))\n",
    "print('Over 12:', np.sum(each_user >= 12))\n",
    "print('Over 14:', np.sum(each_user >= 14))\n",
    "print('Over 16:', np.sum(each_user >= 16))\n",
    "print('Over 18:', np.sum(each_user >= 18))\n",
    "print('Over 20:', np.sum(each_user >= 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "random.seed(42)\n",
    "test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in range(usr_nb):\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "                \n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "#         print(len(t_for_train) + len(f_for_train))\n",
    "        \n",
    "    else: #if in test id, choose half of true and other \n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose half true and half false for test \n",
    "        t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t.append(t_for_test)\n",
    "        test_f.append(f_for_test)\n",
    "        \n",
    "        #the others for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "        \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_nb):\n",
    "            writeProgress('Progress:', z, usr_nb)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1=np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/grid/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 150, 200, 250, 300]\n"
     ]
    }
   ],
   "source": [
    "search_list = [i for i in range(100, 350, 50)]\n",
    "print(search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-76793f7c8ee2>:142: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E100\n",
      "Start time: Thu Mar 19 12:00:23 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.58085641]]\n",
      "train_auc:          0.7505185979971387\n",
      "\tCurrent time: Thu Mar 19 14:47:57 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.52716059]]\n",
      "train_auc:          0.7946396638054364\n",
      "\tCurrent time: Thu Mar 19 17:35:54 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.50233844]]\n",
      "train_auc:          0.816295600858369\n",
      "\tCurrent time: Thu Mar 19 20:23:46 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.48458729]]\n",
      "train_auc:          0.8278254649499285\n",
      "\tCurrent time: Thu Mar 19 23:12:49 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.47247589]]\n",
      "train_auc:          0.83693669527897\n",
      "\tCurrent time: Fri Mar 20 02:02:33 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.46357921]]\n",
      "train_auc:          0.8443043633762518\n",
      "\tCurrent time: Fri Mar 20 04:51:53 2020  sec\n",
      "==================================================\n",
      "Total cost time: 60688.25814437866  sec\n",
      "End time: Fri Mar 20 04:51:53 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.5808564061941166, 0.527160592140558, 0.5023384410765379, 0.4845872870842275, 0.4724758863108011, 0.46357921332930974]\n",
      "Acc: [0.7505185979971387, 0.7946396638054364, 0.816295600858369, 0.8278254649499285, 0.83693669527897, 0.8443043633762518]\n",
      "==================================================\n",
      "==================================================\n",
      "==================================================\n",
      "MRM_E150\n",
      "Start time: Fri Mar 20 04:51:54 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.5911392]]\n",
      "train_auc:          0.7563662374821173\n",
      "\tCurrent time: Fri Mar 20 07:51:18 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "Progress:40.14%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76793f7c8ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxuij\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mloss_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-564b0add271a>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(SAVE_NAME)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                    \u001b[0ml_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_id_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                    \u001b[0mpositive_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                    r: r_3, image_i: image_1, image_j: image_2})\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     '''Observe all params\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3hU1b3/8feXEAjInURFwiUqiAEFccQLavFabEVatS1QrNpW7DlFra39HVptVTz1Rz2ntdZyWtFStaLUyrFFq1Kt1dp6gYCAAnIVJYgKARXkmvA9f6wdMkkmyYRMMsnk83qe/WT2bWZt9PnMmrXXXsvcHRERyVxt0l0AERFpXAp6EZEMp6AXEclwCnoRkQynoBcRyXAKehGRDKegl4xnZllmtsPM+qby2IMox3+a2f2pfl+RurRNdwFEqjKzHXGrHYE9QFm0frW7z6rP+7l7GdAp1ceKtBQKeml23P1A0JrZeuCb7v5cTcebWVt3L22Ksom0RGq6kRYnagL5g5k9YmbbgYlmdqqZvWpmH5nZJjP7pZllR8e3NTM3s/7R+kPR/qfNbLuZvWJmBfU9Ntp/gZmtMrOPzexuM/uXmV2R5HV80cyWRWV+3syOidv3QzN7z8w+MbO3zGxUtP0UM1sUbf/AzP4rBf+kkuEU9NJSfRF4GOgK/AEoBa4DcoGRwGjg6lrOnwD8COgBvAvcVt9jzexQ4FHg+9Hnvg2MSKbwZnYs8HvgGiAPeA6Ya2bZZjY4Kvtwd+8CXBB9LsDdwH9F248GHkvm86R1U9BLS/VPd3/C3fe7+y53X+Dur7l7qbuvA2YAn6nl/Mfcvcjd9wGzgGEHceyFwGJ3/3O0705gS5LlHwfMdffno3OnEb60TiZ8aeUAg6NmqbejawLYBwwws57uvt3dX0vy86QVU9BLS7UhfsXMBpnZX8zsfTP7BJhKqGXX5P241zup/QZsTcceEV8ODyMEFidR9vJz34k7d390bm93Xwl8j3ANH0ZNVIdHh14JFAIrzWy+mX0uyc+TVkxBLy1V1WFX7wHeBI6OmjV+DFgjl2ETkF++YmYG9E7y3PeAfnHntoneayOAuz/k7iOBAiAL+P/R9pXuPg44FPgZMMfMchp+KZLJFPSSKToDHwOfRu3ftbXPp8qTwHAzG2NmbQn3CPKSPPdR4CIzGxXdNP4+sB14zcyONbOzzKw9sCta9gOY2WVmlhv9AviY8IW3P7WXJZlGQS+Z4nvA5YSwvIdwg7ZRufsHwFeAnwMlwFHA64R+/3Wdu4xQ3l8Dmwk3jy+K2uvbA3cQ2vvfB7oDN0anfg5YEfU2+m/gK+6+N4WXJRnINPGISGqYWRahSeZSd38p3eURKacavUgDmNloM+sWNbP8iNArZn6aiyVSiYJepGFOB9YRml8+C3zR3etsuhFpSmq6ERHJcKrRi4hkuGY3qFlubq73798/3cUQEWlRFi5cuMXdE3bvbXZB379/f4qKitJdDBGRFsXM3qlpn5puREQynIJeRCTDJRX0UV/hlWa2xsymJNjf18z+bmavm9nS8oGWzKy/me0ys8XR8ptUX4CIiNSuzjb66Gm/6cB5hNH1FpjZXHdfHnfYTcCj7v5rMysEngL6R/vWunttQ8CKiEgjSqZGPwJY4+7rojE1ZgNjqxzjQJfodVfCY+AiItIMJBP0vak89ncx1YdivYUwnVsxoTZ/Tdy+gqhJ50UzOyPRB5jZJDMrMrOizZs3J196ERGpU6puxo4H7nf3fMLoer+PxtfeBPR19xOA7wIPm1mXqie7+wx3j7l7LC8v2VFeRUQkGcn0o98I9IlbPzA5QpxvEIZZxd1fiSZCyHX3D4mGbHX3hWa2FhgIqKO8iLQq7rB7N3z0UeVl27aK17m5MGlS6j87maBfQJijsoAQ8OMIkyXHexc4B7g/mvQhB9hsZnnAVncvM7MjgQGEAaBERFqcREFdU2gnWvbWMXPAKaekKejdvdTMJgPzCFOazXT3ZWY2FShy97mESR/uNbPrCTdmr3B3N7Mzgalmto8wC8633H1r6i9DRKRue/bUHsR1BfeeOsYlbdcOuneHbt3C0r07FBRUXi9/XXXp2hVyGmlSyGY3emUsFnMNgSAiiezdCx9/nFztOdGya1ft75+dXXsYV12qHttYQZ0MM1vo7rFE+5rdWDcikvn27YOtW2HLlpqXrVurB/XOnbW/b9u21YM4Pz/54O7QAayxp5RPAwW9iDRIWVnl0C4pqT3At2wJtfKadOoUbkr26BGCulev5Jo+unWDjh0zM6gbSkEvIgfs3x9qzjUFdKIQ37Yt9ChJpGPHENq5udCzJxx5ZMV6oqVnT2jfvmmvuTVQ0ItkKPdQc062ll1SEpb9+xO/X7t2kJdXEconnFARzjWFdseOTXvNkpiCXqQFcIcdO5KvZZdvLy1N/H5t21YO5SFDEgd1/Pohh6hZpKVS0IukUVkZbN4M770HmzZVX8q3f/BBzX2w27SpHM4DB8Jpp9XeRNK5s0K7NVHQizSCffvg/fdrD+/yAE/UVNKjR7gJ2asXDBoEhx1WudkkfunaNYS9SE0U9CL1sHt33eG9aVNoOql6g9IshPURR4QAHzasIsx79arYfvjhuiEpqaWgFyG0f9cV3ps2hR4mVWVlhXDu1Qv69QuPsccHd/ly2GGhbVykqel/O8lY5b1O6grvTZtg+/bq57drVxHSxxwDZ51VObjLl7w8NZ1I86aglxbHPfQoqSu8N21K/Mh7x44VNe5hw+CCCxI3oXTvrhuWkhkU9NKslZTAkiUVy+LFsGJF4h4oXbtWhHV580miJhT1OJHWRkEvzUJZGaxdWxHm5cFeXFxxTK9eMHQonHce9OlTvQlFD+eIJKaglya3YwcsXVq5lv7GGxUDVmVlwbHHwqhRIdjLl0MPTWuxRVosBb00GnfYsKFyoC9ZEmru5V0Pu3cPIX7VVeHvsGFQWKjuhSKppKCXlNizB5Yvr9zssmRJ5e6IRx8dwvzyyytq6X36qL1cpLEp6KXePvywei39rbcqxlXp2BGOPx6+/OWKWvpxx4XhZ0Wk6SUV9GY2GriLMJXgfe4+rcr+vsADQLfomCnu/lS07weEycPLgGvdfV7qii+NqbQUVq+uXkvftKnimPz8EOZjx1bU0o86KrSzi0jzUGfQm1kWMB04DygGFpjZXHdfHnfYTcCj7v5rMysEngL6R6/HAYOBI4DnzGygu5el+kKkYT7+uPoN0jffDI/8Q5hibfBgOP/8yjdIe/ZMb7lFpG7J1OhHAGvcfR2Amc0GxgLxQe9Al+h1V+C96PVYYLa77wHeNrM10fu9koKyy0Fwh/Xrq3djfPvtimNyc0OI//u/h2aXoUPDwFrt2qWt2CLSAMkEfW9gQ9x6MXBylWNuAf5qZtcAhwDnxp37apVze1f9ADObBEwC6Nu3bzLlliTs2hVq5fG19KVL4ZNPwn6zMKTtiBGVe7306qUbpCKZJFU3Y8cD97v7z8zsVOD3ZjYk2ZPdfQYwAyAWi9UwKZnUxD0MiVu1lr5yZcUQuJ07hxukEydW1NKHDNFDRiKtQTJBvxHoE7eeH22L9w1gNIC7v2JmOUBukufKQdi+Hf74x7AsXBgmryjXr18I8y99qaItvaBAA2+JtFbJBP0CYICZFRBCehwwocox7wLnAPeb2bFADrAZmAs8bGY/J9yMHQDMT1HZW539++HFF+H+++Gxx8KTpAMGwJgxFc0uxx8P3bqlu6Qi0pzUGfTuXmpmk4F5hK6TM919mZlNBYrcfS7wPeBeM7uecGP2Cnd3YJmZPUq4cVsKfFs9burv7bfhgQfCsn49dOkSmmCuvBJOPlnt6SJSO/Oq0+CkWSwW86KionQXI+127IA5c+B3vwu1eDM499wQ7l/4AnTokO4SikhzYmYL3T2WaJ+ejG1G3OGll0K4//GP8OmnoWnmJz+Byy4LwwWIiNSXgr4ZeOediqaZdetCD5nx4+GKK+C009Q0IyINo6BPk507Q9PM/ffD88+HbeecA7feCl/8IhxySFqLJyIZREHfhNzh5ZdD08yjj4YukkceCVOnwte+FrpFioikmoK+CWzYAA8+GGrva9aE2vqXvxyaZs44Q00zItK4FPSNZNcuePzxEO7PPRdq86NGwU03wSWXaMheEWk6CvoUcodXXw3hPnt2GFOmf3/48Y/DZBsFBekuoYi0Rgr6FNi4EX7/+xDwK1eG8WMuvTT0eT/zTA09ICLppaA/SLt3w5//HML9r38NwxOccQb8x3+EkO/cOd0lFBEJFPT14A4LFoReM7Nnw0cfQd++cOONodfM0Uenu4QiItUp6JOwaRM89FCovS9fHoYfuOSS0GvmrLPUNCMizZuCvgZ79sATT4Ta+zPPhKaZkSPh3nvD8L9du6a7hCIiyVHQx3EPY7vffz88/DBs2xYmv54yJfSaGTgw3SUUEak/BT3wwQcVTTNvvgk5OWEYgiuuCMMSZGWlu4QiIgev1Qb93r3w5JMh3J96CsrK4JRT4De/ga98RZN3iEjmaHVB//rrIdxnzYKSkjAR9g03hNr7oEHpLp2ISOq1iqDfvDkE+/33h0mz27ULk3dceWWYzKNtq/hXEJHWKqmIM7PRwF2EqQTvc/dpVfbfCZwVrXYEDnX3btG+MuCNaN+77n5RKgpel337QpPM/feHJprSUjjpJPif/wlNMz16NEUpRETSr86gN7MsYDpwHlAMLDCzue6+vPwYd78+7vhrgBPi3mKXuw9LXZFrt3RpCPeHHgo1+cMOg+98JzTNDB7cVKUQEWk+kqnRjwDWuPs6ADObDYwlTPidyHjg5tQUL3nvvAMXXwyLFkF2NowdG8L9s59V04yItG7JRGBvYEPcejFwcqIDzawfUAA8H7c5x8yKgFJgmrv/KcF5k4BJAH379k2u5FUccQTk5sLdd4dp+Hr2PKi3ERHJOKmu644DHnP3srht/dx9o5kdCTxvZm+4+9r4k9x9BjADIBaL+cF8cHY2zJt3sMUWEclcyYzSshHoE7eeH21LZBzwSPwGd98Y/V0HvEDl9nsREWlkyQT9AmCAmRWYWTtCmM+tepCZDQK6A6/EbetuZu2j17nASGpu2xcRkUZQZ9ONu5ea2WRgHqF75Ux3X2ZmU4Eidy8P/XHAbHePb3o5FrjHzPYTvlSmxffWERGRxmeVczn9YrGYFxUVpbsYIiItipktdPdYon0aSV1EJMMp6EVEMpyCXkQkwynoRUQynIJeRCTDKehFRDKcgl5EJMMp6EVEMpyCXkQkwynoRUQynIJeRCTDKehFRDKcgl5EJMMp6EVEMpyCXkQkwynoRUQynIJeRCTDJRX0ZjbazFaa2Rozm5Jg/51mtjhaVpnZR3H7Ljez1dFyeSoLLyIidatzzlgzywKmA+cBxcACM5sbP/eru18fd/w1wAnR6x7AzUAMcGBhdO62lF6FiIjUKJka/Qhgjbuvc/e9wGxgbC3HjwceiV5/FnjW3bdG4f4sMLohBRYRkfpJJuh7Axvi1oujbdWYWT+gAHi+Puea2SQzKzKzos2bNydTbhERSVKqb8aOAx5z97L6nOTuM9w95u6xvLy8FBdJRKR1SyboNwJ94tbzo22JjKOi2aa+54qISCNIJugXAAPMrMDM2hHCfG7Vg8xsENAdeCVu8zzgfDPrbmbdgfOjbSIi0kTq7HXj7qVmNpkQ0FnATHdfZmZTgSJ3Lw/9ccBsd/e4c7ea2W2ELwuAqe6+NbWXICIitbG4XG4WYrGYFxUVpbsYIiItipktdPdYon16MlZEJMMp6EVEMlydbfQiIgD79u2juLiY3bt3p7sorVpOTg75+flkZ2cnfY6CXkSSUlxcTOfOnenfvz9mlu7itEruTklJCcXFxRQUFCR9nppuRCQpu3fvpmfPngr5NDIzevbsWe9fVQp6EUmaQj79Dua/gYJeRFqEkpIShg0bxrBhwzj88MPp3bv3gfW9e/cm9R5XXnklK1eurPWY6dOnM2vWrFQUudlQG72ItAg9e/Zk8eLFANxyyy106tSJG264odIx7o6706ZN4jrs7373uzo/59vf/nbDC9vMqEYvIi3amjVrKCws5Ktf/SqDBw9m06ZNTJo0iVgsxuDBg5k6deqBY08//XQWL15MaWkp3bp1Y8qUKQwdOpRTTz2VDz/8EICbbrqJX/ziFweOnzJlCiNGjOCYY47h5ZdfBuDTTz/lkksuobCwkEsvvZRYLHbgSyjezTffzEknncSQIUP41re+RfkDqqtWreLss89m6NChDB8+nPXr1wNw++23c9xxxzF06FBuvPHGlP0bqUYvIvX2ne9AglxrkGHDIMrXenvrrbd48MEHicXCg6HTpk2jR48elJaWctZZZ3HppZdSWFhY6ZyPP/6Yz3zmM0ybNo3vfve7zJw5kylTqk2gh7szf/585s6dy9SpU3nmmWe4++67Ofzww5kzZw5Llixh+PDhCct13XXXceutt+LuTJgwgWeeeYYLLriA8ePHc8sttzBmzBh2797N/v37eeKJJ3j66aeZP38+HTp0YOvW1I0Woxq9iLR4Rx111IGQB3jkkUcYPnw4w4cPZ8WKFSxfvrzaOR06dOCCCy4A4MQTTzxQq67q4osvrnbMP//5T8aNGwfA0KFDGTx4cMJz//a3vzFixAiGDh3Kiy++yLJly9i2bRtbtmxhzJgxQOgX37FjR5577jm+/vWv06FDBwB69OhR/3+IGqhGLyL1drA178ZyyCGHHHi9evVq7rrrLubPn0+3bt2YOHFiwu6I7dq1O/A6KyuL0tLShO/dvn37Oo9JZOfOnUyePJlFixbRu3dvbrrpprQ9bKYavYhklE8++YTOnTvTpUsXNm3axLx5qR8ZfeTIkTz66KMAvPHGGwl/MezatYs2bdqQm5vL9u3bmTNnDgDdu3cnLy+PJ554AgjPJ+zcuZPzzjuPmTNnsmvXLoCUNt2oRi8iGWX48OEUFhYyaNAg+vXrx8iRI1P+Gddccw1f+9rXKCwsPLB07dq10jE9e/bk8ssvp7CwkF69enHyyScf2Ddr1iyuvvpqbrzxRtq1a8ecOXO48MILWbJkCbFYjOzsbMaMGcNtt92WkvJqmGIRScqKFSs49thj012MZqG0tJTS0lJycnJYvXo1559/PqtXr6Zt26apOyf6b1HbMMWq0YuI1NOOHTs455xzKC0txd255557mizkD0bzLZmISDPVrVs3Fi5cmO5iJC2pm7FmNtrMVprZGjOr3tE0HPNlM1tuZsvM7OG47WVmtjhaqs01KyIijavOGr2ZZQHTgfOAYmCBmc119+VxxwwAfgCMdPdtZnZo3FvscvdhKS63iIgkKZka/Qhgjbuvc/e9wGxgbJVjrgKmu/s2AHf/MLXFFBGRg5VM0PcGNsStF0fb4g0EBprZv8zsVTMbHbcvx8yKou1fSPQBZjYpOqZo8+bN9boAERGpXaoemGoLDABGAeOBe82sW7SvX9TlZwLwCzM7qurJ7j7D3WPuHsvLy0tRkUQkk7TEYYrLB1FLt2R63WwE+sSt50fb4hUDr7n7PuBtM1tFCP4F7r4RwN3XmdkLwAnA2oYWXERaFw1TfPCSqdEvAAaYWYGZtQPGAVV7z/yJUJvHzHIJTTnrzKy7mbWP2z4SqP6ssIjIQWrOwxTHe+ihhzjuuOMYMmQIP/zhD4Hw4NVll112YPsvf/lLAO68804KCws5/vjjmThxYoP/jeqs0bt7qZlNBuYBWcBMd19mZlOBInefG+0738yWA2XA9929xMxOA+4xs/2EL5Vp8b11RKSFambjFDfXYYrLFRcXc9NNN1FUVETXrl0599xzefLJJ8nLy2PLli288cYbAHz00UcA3HHHHbzzzju0a9fuwLaGSKqN3t2fcveB7n6Uu/8k2vbjKOTx4LvuXujux7n77Gj7y9H60OjvbxtcYhGRKprrMMXlXnvtNc4++2xyc3PJzs5mwoQJ/OMf/+Doo49m5cqVXHvttcybN+/AeDmDBw9m4sSJzJo1i+zs7Hr9WySiJ2NFpP6a2TjFzXGY4mT07NmTpUuX8vTTTzN9+nTmzJnDjBkzmDdvHi+++CJz587l9ttvZ+nSpWRlZR3052iYYhHJKM1lmOJ4J598Mn//+98pKSmhtLSU2bNn85nPfIbNmzfj7nzpS19i6tSpLFq0iLKyMoqLizn77LO544472LJlCzt37mxQeVWjF5GM0lyGKY6Xn5/PbbfdxqhRo3B3xowZw+c//3kWLVrEN77xDdwdM+OnP/0ppaWlTJgwge3bt7N//35uuOEGOnfu3KDyaphiEUmKhimuoGGKRUQynIYpFhHJcBk5TLGIiLRcCnoRSVpzu6fXGh3MfwMFvYgkJScnh5KSEoV9Grk7JSUl5OTk1Os8tdGLSFLy8/MpLi5GQ4mnV05ODvn5+fU6R0EvIknJzs6moKAg3cWQg6CmGxGRDKegFxHJcAp6EZEMp6AXEclwCnoRkQynoBcRyXBJBb2ZjTazlWa2xsyqz7UVjvmymS03s2Vm9nDc9svNbHW0XJ6qgouISHLq7EdvZlnAdOA8oBhYYGZz4+d+NbMBwA+Ake6+zcwOjbb3AG4GYoADC6Nzt6X+UkREJJFkavQjgDXuvs7d9wKzgbFVjrkKmF4e4O7+YbT9s8Cz7r412vcsMDo1RRcRkWQkE/S9gQ1x68XRtngDgYFm9i8ze9XMRtfjXMxskpkVmVmRHq8WEUmtVN2MbQsMAEYB44F7zaxbsie7+wx3j7l7LC8vL0VFEhERSC7oNwJ94tbzo23xioG57r7P3d8GVhGCP5lzRUSkESUT9AuAAWZWYGbtgHHA3CrH/IlQm8fMcglNOeuAecD5ZtbdzLoD50fbRESkidTZ68bdS81sMiGgs4CZ7r7MzKYCRe4+l4pAXw6UAd939xIAM7uN8GUBMNXdtzbGhYiISGLW3CYRiMViXlRUlO5iiIi0KGa20N1jifbpyVgRkQynoBcRyXAKehGRDJc5Qb93L5xxBvzqV/Dpp+kujYhIs5E5Qf/++1BWBtdcA/36wc03g56yFRHJoKDv2xdefhn++U84/XSYOjVs+7d/gzVr0l06EZG0yZygLzdyJPzpT7BiBUycCDNnwsCBcOml8Npr6S6diEiTy7ygLzdoENx7L7zzDvzgB/C3v8Epp8CZZ8KTT8L+/ekuoYhIk8jcoC93+OHwk5/Au+/CnXeG4B8zBoYMCbX9PXvSXUIRkUaV+UFfrnNn+M53Qnv9rFnQvj184xtQUAA//Sl89FG6Sygi0ihaT9CXy86GCRNg0SL4619DzX7KFOjTB773Pdiwoe73EBFpQVpf0Jczg/POC2H/+uswdizcdRcceSRcdhksXZruEoqIpETrDfp4w4bBQw/B2rUweTI8/jgMHQqjR4ebuM1s4DcRkfpQ0Mfr1y/csN2wAW6/HRYvhnPPhVgMZs+G0tJ0l1BEpN4U9Il07x66ZK5fH7pofvopjB8PAwbAL3+pIRZEpEVR0NcmJwe++U1Yvhz+/GfIz4frrgs3bn/0I/jgg3SXUESkTgr6ZLRpAxddBC+9FIZZGDUq9M3v1w+uvhpWrUp3CUVEapRU0JvZaDNbaWZrzGxKgv1XmNlmM1scLd+M21cWt73qXLMtz6mnwv/+L7z1Flx+OTzwQHgK9+KL4ZVX0l06EZFq6gx6M8sCpgMXAIXAeDMrTHDoH9x9WLTcF7d9V9z2i1JT7GZg4EC4557wpO2NN8ILL8Bpp4UB1f78Zw2xICLNRjI1+hHAGndf5+57gdnA2MYtVgty2GFw221hiIW77oLiYvjCF6CwEO67D3bvTncJRaSVSyboewPxj4sWR9uqusTMlprZY2bWJ257jpkVmdmrZvaFRB9gZpOiY4o2t9Qx5Dt1gmuvDUMsPPIIdOwIV10F/fuHrprbtqW7hCLSSqXqZuwTQH93Px54Fnggbl+/aGbyCcAvzOyoqie7+wx3j7l7LC8vL0VFSpO2bWHcOFi4EJ57LjyMdeONoafO9deHph4RkSaUTNBvBOJr6PnRtgPcvcTdy4eBvA84MW7fxujvOuAF4IQGlLflMINzzoFnnoElS8LN2l/9Co46Cr761fAwlohIE0gm6BcAA8yswMzaAeOASr1nzKxX3OpFwIpoe3czax+9zgVGAstTUfAW5fjj4cEHYd260A9/7lw44QQ4/3x49lkNsSAijarOoHf3UmAyMI8Q4I+6+zIzm2pm5b1orjWzZWa2BLgWuCLafixQFG3/OzDN3Vtf0Jfr0wd+9rMwxMK0afDGGyHshw8PQyfv25fuEopIBjJvZrXJWCzmRUVF6S5G09izJwT8f/93mPqwb9/Qjv/Nb4abuyIiSTKzhdH90Gr0ZGw6tW8PX/86vPkmPPFEeNL2+utDzf+HP4T33093CUUkAyjom4M2beDCC+Ef/4BXXw03cadNC8F/1VXhKVwRkYOkoG9uTj4ZHnsMVq4Mtf2HHoJjjw0To/zrX+kunYi0QAr65mrAAPj1r0O/+x//OIT86aeHYRYefxzKytJdQhFpIRT0zd2hh8Ktt4bAv/vu0G5/8cWhln/PPbBrV7pLKCLNnIK+pTjkkDDN4apV8Ic/QNeu8K1vhZ46X/lK6Lb50kuaFEVEqlH3ypbKHV58EWbMCMMjr18ftrdpA0OGhLb+ESPCUlgYhmYQkYxVW/dKBX2m+PBDWLAAXnsN5s8PS/lAah07woknVg7/vn3DMA0ikhEU9K2RO6xdGwK/PPxffz08pAVheOXy0B8xAk46KcyVKyItUm1Br9/zmcoMjj46LBMmhG1794ZhF+LD/8knK8baGTCgcq1/6NAwb66ItGiq0bd2H38chlQuD/7XXoNNm8K+7OwQ9vHhP3BguA8gIs2Kmm6kfjZurFzrX7AAduwI+7p0Cc088eHfq1ft7ycijU5BLw1TVhae1I0P/6VLobQ07M/PD4FfHv4nngidO6e3zCKtjIJeUm/XrjB5Snwvn7Vrwz6z0KUzPvyHDAlNQSLSKBT00jRKSqp38dyyJezLyQnj7sc3+RQUqIunSIoo6CU93MODXPFNPgsXwu7dYcMYDgkAAAncSURBVH/PnpVr/SedBLm5aS2ySEul7pWSHmah1l5QEIZpgDCL1rJllWv9zzxT0cXzyCMrh/8JJ0CHDum7BpEMkFSN3sxGA3cBWcB97j6tyv4rgP+iYtLwX7n7fdG+y4Gbou3/6e4P1PZZqtG3Qtu3w6JFlcN/w4awr21bOO64yuE/aBBkZaW3zCLNTIOabswsC1gFnAcUEyYLHx8/92sU9DF3n1zl3B5AERADHFgInOju22r6PAW9AKEvf3x7/4IFoc8/hAHeBg6EY44JS/nrgQPV20darYY23YwA1rj7uujNZgNjgWQm+f4s8Ky7b43OfRYYDTySTMGlFevVCy66KCwA+/fD6tUV7fwrV4YvgT/8oaLZB+CIIyp/CZR/AfTvr4HdpNVK5v/83sCGuPVi4OQEx11iZmcSav/Xu/uGGs7tXfVEM5sETALo27dvciWX1qVNm4rgvuyyiu27d4dunStXVl4efbRiUDcIXTuPPrr6r4BjjtENYMl4qariPAE84u57zOxq4AHg7GRPdvcZwAwITTcpKpO0Bjk5MHhwWKrasqUi+Fetqnj9l7+Em8LlevRI/Cvg6KM11o9khGSCfiPQJ249n4qbrgC4e0nc6n3AHXHnjqpy7gv1LaTIQcnNDcvIkZW3l5aGGbvifwGsWgXPPgsPxPUVMAtNPlV/ARxzDPTurWcApMVIJugXAAPMrIAQ3OOACfEHmFkvd49GwuIiYEX0eh5wu5mVj397PvCDBpdapCHatoWjjgrL5z5Xed/27RW1//hfAVVn7+rYMfEN4WOO0Q1haXbqDHp3LzWzyYTQzgJmuvsyM5sKFLn7XOBaM7sIKAW2AldE5241s9sIXxYAU8tvzIo0S507h7F6Tjyx8nZ3eO+96r8CFiyAP/4x3Cwu16tX4l8BuiEsaaInY0Uaas8eWLOm8i+A8mVrXL0mOzv8iqjphrCagqQB9GSsSGNq377mG8IlJdV/BaxcCU8/HSaCKde9e+IbwgMG6IawNJhq9CLpUFYWxgGq+itg1aowH0A5M+jXLwR+797hOYGqfw87TE1Cohq9SLOTlVVxQ/iCCyrv27Gj+g3htWthxYrwxHBZWeXj27QJYZ/oSyD+b/fuah5qpRT0Is1Np05hSOfhw6vvKyuDzZtDrf+99yr+lr9evx7+9a/QZFRV+/Z1fxkccUToUSQZRUEv0pJkZcHhh4elas+geLt3h9p//JdA/N/XXw8Tw+/cWf3crl3r/jI4/HA1F7Ug+i8lkolyciqGiK6Je3huoOqXQPzf558PXxjl00aWM6u7ueiII8KcA2ouSjsFvUhrZRYme+/SBY49tubj9u8PzUWJvgzeew/efRdefTUcU1W7dnV/GfTuHUYklUajoBeR2pXf7D3ssDARTE327IH336/5/sHSpaFb6Y4d1c/t0qX6l0CvXuEXQc+e4TmD8r+dOulXQj0p6EUkNdq3D11B+/Wr/bj45qJEvxJeeCE0F8UPPBcvO7si+Kt+CcT/jX/dtWv4wmqlFPQi0rQ6dw6zhA0aVPMx+/eHYaZLSsIopCUllV/H/12xomK9atfTcllZYZTS+nxBdO+eMTOZKehFpPlp06YidAcOTO4cd/jkk8RfBlW/MNatC+MUbdlS+QnleGYh7Gv6lZDoC6Jnz/CLo5lR0ItIZjALTTRdu4YH0ZLhHkYlretXQ0kJFBfDkiXhdaJuqeW6dKm9GSnRvkYe5kJBLyKtl1m4udupUxhdNFm7dtX8ayF+2+bNoWmppCTcm6jJIYeEwD/tNHgk9TOtKuhFROqrQwfIzw9LsvburftXQ+9qM62mhIJeRKQptGsXuoz26tXkH916+xuJiLQSCnoRkQyXVNCb2WgzW2lma8xsSi3HXWJmbmaxaL2/me0ys8XR8ptUFVxERJJTZxu9mWUB04HzgGJggZnNdfflVY7rDFwHvFblLda6+7AUlVdEROopmRr9CGCNu69z973AbGBsguNuA34K7E5h+UREpIGSCfrewIa49eJo2wFmNhzo4+5/SXB+gZm9bmYvmtkZiT7AzCaZWZGZFW1ONAKeiIgctAbfjDWzNsDPge8l2L0J6OvuJwDfBR42sy5VD3L3Ge4ec/dYXl5eQ4skIiJxkgn6jUCfuPX8aFu5zsAQ4AUzWw+cAsw1s5i773H3EgB3XwisBZIcuEJERFLB3L32A8zaAquAcwgBvwCY4O7Lajj+BeAGdy8yszxgq7uXmdmRwEvAce6+tZbP2wy8czAXE8kFtjTg/JaotV1za7te0DW3Fg255n7unrBJpM5eN+5eamaTgXlAFjDT3ZeZ2VSgyN3n1nL6mcBUM9sH7Ae+VVvIR5/XoLYbMyty91hD3qOlaW3X3NquF3TNrUVjXXNSQyC4+1PAU1W2/biGY0fFvZ4DzGlA+UREpIH0ZKyISIbLxKCfke4CpEFru+bWdr2ga24tGuWa67wZKyIiLVsm1uhFRCSOgl5EJMNlTNCb2Uwz+9DM3kx3WZqCmfUxs7+b2XIzW2Zm16W7TI3NzHLMbL6ZLYmu+dZ0l6mpmFlWNJTIk+kuS1Mws/Vm9kY06m1RusvTFMysm5k9ZmZvmdkKMzs1Ze+dKW30ZnYmsAN40N2HpLs8jc3MegG93H1RNHLoQuALVUcVzSRmZsAh7r7DzLKBfwLXufuraS5aozOz7wIxoIu7X5ju8jS26Cn7mLu3mgemzOwB4CV3v8/M2gEd3f2jVLx3xtTo3f0fQK0PY2USd9/k7oui19uBFVQZbC7TeLAjWs2OlsyoqdTCzPKBzwP3pbss0jjMrCvhAdPfArj73lSFPGRQ0LdmZtYfOIHqcwFknKgJYzHwIfCsu2f8NQO/AP4f4eny1sKBv5rZQjOblO7CNIECYDPwu6iJ7j4zOyRVb66gb+HMrBPh6ePvuPsn6S5PY3P3smgim3xghJlldDOdmV0IfBgNCtianO7uw4ELgG9HTbOZrC0wHPh1NNrvp0CNs/nVl4K+BYvaqecAs9z9f9NdnqYU/az9OzA63WVpZCOBi6I269nA2Wb2UHqL1PjcfWP090PgccIESJmsGCiO+4X6GCH4U0JB30JFNyZ/C6xw95+nuzxNwczyzKxb9LoDYXrLt9Jbqsbl7j9w93x37w+MA55394lpLlajMrNDog4GRM0X5wMZ3ZvO3d8HNpjZMdGmc4CUdaxIalCzlsDMHgFGAblmVgzc7O6/TW+pGtVI4DLgjajNGuCH0QB0maoX8EA0j3Eb4FF3bxXdDVuZw4DHQ12GtsDD7v5MeovUJK4BZkU9btYBV6bqjTOme6WIiCSmphsRkQynoBcRyXAKehGRDKegFxHJcAp6EZEMp6AXEclwCnoRkQz3f/nr9oaIUV/zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for embedding_dims in search_list:\n",
    "    SAVE_NAME = 'MRM_E{}'.format(embedding_dims)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
