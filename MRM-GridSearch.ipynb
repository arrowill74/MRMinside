{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2372)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "150 32\n",
      "64 2372\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "print(latent_dim, ft_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50: 125\n",
      "Over 100: 89\n",
      "Over 150: 58\n",
      "Over 200: 42\n",
      "Over 250: 31\n",
      "Over 300: 21\n"
     ]
    }
   ],
   "source": [
    "print('Over 50:', np.sum(moive_followers >= 50))\n",
    "print('Over 100:', np.sum(moive_followers >= 100))\n",
    "print('Over 150:', np.sum(moive_followers >= 150))\n",
    "print('Over 200:', np.sum(moive_followers >= 200))\n",
    "print('Over 250:', np.sum(moive_followers >= 250))\n",
    "print('Over 300:', np.sum(moive_followers >= 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) [  0   2   3   4   9  12  24  28  30  34  40  44  49  55  57  58  60  66\n",
      "  68  78  80  81  84  86  87  99 101 102 112 119 122 123 125 126 127 128\n",
      " 129 134 144 156 161 164]\n",
      "32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]\n"
     ]
    }
   ],
   "source": [
    "over200_idx = np.nonzero(moive_followers >= 200)[0]\n",
    "print(over200_idx.shape, over200_idx)\n",
    "\n",
    "random.seed(42)\n",
    "movie_test_idx = sorted(random.sample(list(over200_idx), movie_test_amount))\n",
    "print(len(movie_test_idx), movie_test_idx) # 32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(usr_following, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "asc = np.sort(each_user)\n",
    "# print(each_user)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n"
     ]
    }
   ],
   "source": [
    "print('Over 10:', np.sum(each_user >= 10))\n",
    "print('Over 12:', np.sum(each_user >= 12))\n",
    "print('Over 14:', np.sum(each_user >= 14))\n",
    "print('Over 16:', np.sum(each_user >= 16))\n",
    "print('Over 18:', np.sum(each_user >= 18))\n",
    "print('Over 20:', np.sum(each_user >= 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "random.seed(42)\n",
    "test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in range(usr_nb):\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "                \n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "#         print(len(t_for_train) + len(f_for_train))\n",
    "        \n",
    "    else: #if in test id, choose half of true and other \n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose half true and half false for test \n",
    "        t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t.append(t_for_test)\n",
    "        test_f.append(f_for_test)\n",
    "        \n",
    "        #the others for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "        \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_nb):\n",
    "            writeProgress('Progress:', z, usr_nb)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1=np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/grid/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240]\n"
     ]
    }
   ],
   "source": [
    "search_list = [240]\n",
    "print(search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-5081143ce571>:144: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E240_19\n",
      "Start time: Sat Apr 25 00:20:23 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.4498693]]\n",
      "train_auc:          0.8124463519313305\n",
      "\tCurrent time: Sat Apr 25 03:43:58 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.27134102]]\n",
      "train_auc:          0.8985962088698141\n",
      "\tCurrent time: Sat Apr 25 07:07:19 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.17810439]]\n",
      "train_auc:          0.9431017525035765\n",
      "\tCurrent time: Sat Apr 25 10:30:24 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.12804796]]\n",
      "train_auc:          0.9659334763948498\n",
      "\tCurrent time: Sat Apr 25 13:53:54 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.10100453]]\n",
      "train_auc:          0.9767525035765379\n",
      "\tCurrent time: Sat Apr 25 17:18:05 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.08247301]]\n",
      "train_auc:          0.9832573319027181\n",
      "\tCurrent time: Sat Apr 25 20:42:10 2020  sec\n",
      "==================================================\n",
      "Total cost time: 73304.97525000572  sec\n",
      "End time: Sat Apr 25 20:42:10 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.4498693026868741, 0.27134101660295956, 0.17810439299445638, 0.12804795948732564, 0.10100453039777807, 0.08247300831545064]\n",
      "Acc: [0.8124463519313305, 0.8985962088698141, 0.9431017525035765, 0.9659334763948498, 0.9767525035765379, 0.9832573319027181]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 18\n",
    "for embedding_dims in search_list:\n",
    "    idx += 1\n",
    "    SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, idx)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MRM_E240_20\n",
      "Start time: Sat Apr 25 20:42:12 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.44927593]]\n",
      "train_auc:          0.8125134120171674\n",
      "\tCurrent time: Sun Apr 26 00:06:51 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "Progress:19.91%\r"
     ]
    }
   ],
   "source": [
    "# idx = 18\n",
    "for embedding_dims in search_list:\n",
    "    idx += 1\n",
    "    SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, idx)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
