{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_E200_10epoch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 4882)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_4882.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "150 32\n",
      "128 4882 200\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 128 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 200\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50: 125\n",
      "Over 100: 89\n",
      "Over 150: 58\n",
      "Over 200: 42\n",
      "Over 250: 31\n",
      "Over 300: 21\n"
     ]
    }
   ],
   "source": [
    "print('Over 50:', np.sum(moive_followers >= 50))\n",
    "print('Over 100:', np.sum(moive_followers >= 100))\n",
    "print('Over 150:', np.sum(moive_followers >= 150))\n",
    "print('Over 200:', np.sum(moive_followers >= 200))\n",
    "print('Over 250:', np.sum(moive_followers >= 250))\n",
    "print('Over 300:', np.sum(moive_followers >= 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) [  0   2   3   4   9  12  24  28  30  34  40  44  49  55  57  58  60  66\n",
      "  68  78  80  81  84  86  87  99 101 102 112 119 122 123 125 126 127 128\n",
      " 129 134 144 156 161 164]\n",
      "32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]\n"
     ]
    }
   ],
   "source": [
    "over200_idx = np.nonzero(moive_followers >= 200)[0]\n",
    "print(over200_idx.shape, over200_idx)\n",
    "\n",
    "random.seed(42)\n",
    "movie_test_idx = sorted(random.sample(list(over200_idx), movie_test_amount))\n",
    "print(len(movie_test_idx), movie_test_idx) # 32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(usr_following, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "asc = np.sort(each_user)\n",
    "# print(each_user)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n"
     ]
    }
   ],
   "source": [
    "print('Over 10:', np.sum(each_user >= 10))\n",
    "print('Over 12:', np.sum(each_user >= 12))\n",
    "print('Over 14:', np.sum(each_user >= 14))\n",
    "print('Over 16:', np.sum(each_user >= 16))\n",
    "print('Over 18:', np.sum(each_user >= 18))\n",
    "print('Over 20:', np.sum(each_user >= 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "random.seed(42)\n",
    "test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in range(usr_nb):\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "                \n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "#         print(len(t_for_train) + len(f_for_train))\n",
    "        \n",
    "    else: #if in test id, choose half of true and other \n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose half true and half false for test \n",
    "        t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t.append(t_for_test)\n",
    "        test_f.append(f_for_test)\n",
    "        \n",
    "        #the others for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "        \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    \n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "    \n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-45fa636fc37a>:95: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "# norm_par = [tf.reduce_sum(tf.multiply(u, u)),\n",
    "#             tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "#             tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "#             tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "#             tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "#             tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "#             tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "#             tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "#             tf.reduce_sum(tf.multiply(embedding,embedding))]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: Sat Mar 14 16:53:30 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.61395583]]\n",
      "train_auc:          0.7869769313304721\n",
      "\tCurrent time: Sat Mar 14 22:24:09 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.54928829]]\n",
      "train_auc:          0.8299400929899857\n",
      "\tCurrent time: Sun Mar 15 03:53:08 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.52603437]]\n",
      "train_auc:          0.8485917381974248\n",
      "\tCurrent time: Sun Mar 15 09:21:55 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.5095818]]\n",
      "train_auc:          0.8603183118741059\n",
      "\tCurrent time: Sun Mar 15 14:49:35 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.50282592]]\n",
      "train_auc:          0.8666845493562232\n",
      "\tCurrent time: Sun Mar 15 20:15:21 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.4953117]]\n",
      "train_auc:          0.8738286838340487\n",
      "\tCurrent time: Mon Mar 16 01:39:33 2020  sec\n",
      "==================================================\n",
      "Epoch: 6\n",
      "total_loss          [[0.49440673]]\n",
      "train_auc:          0.8774320457796853\n",
      "\tCurrent time: Mon Mar 16 06:57:24 2020  sec\n",
      "==================================================\n",
      "Epoch: 7\n",
      "total_loss          [[0.49470889]]\n",
      "train_auc:          0.8794974964234621\n",
      "\tCurrent time: Mon Mar 16 12:08:27 2020  sec\n",
      "==================================================\n",
      "Epoch: 8\n",
      "total_loss          [[0.49471549]]\n",
      "train_auc:          0.8816970672389127\n",
      "\tCurrent time: Mon Mar 16 17:20:59 2020  sec\n",
      "==================================================\n",
      "Epoch: 9\n",
      "total_loss          [[0.48999219]]\n",
      "train_auc:          0.8855776108726753\n",
      "\tCurrent time: Mon Mar 16 22:39:21 2020  sec\n",
      "==================================================\n",
      "Total cost time: 193548.28648924828  sec\n",
      "End time: Mon Mar 16 22:39:21 2020\n"
     ]
    }
   ],
   "source": [
    "print('Start time:', time.ctime())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0 = time.time()\n",
    "\n",
    "train_yes_id=[]\n",
    "\n",
    "for q in range(10):\n",
    "    print('Epoch:',q)\n",
    "    train_auc = 0\n",
    "    total_loss = 0\n",
    "    xuij_auc = 0\n",
    "    length = 0\n",
    "    \n",
    "    for z in range(usr_nb):\n",
    "        writeProgress('Progress:', z, usr_nb)\n",
    "        \"\"\"\n",
    "        yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "        yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "        r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "        \"\"\"\n",
    "        yes = []\n",
    "        yesr = []\n",
    "        \n",
    "#         #選全部的Positive\n",
    "#         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #選全部的電影\n",
    "        sample = all_auxilary\n",
    "        \n",
    "        #change\n",
    "        r_3 = np.zeros(len(sample))\n",
    "         \n",
    "        for b in range(len(sample)):\n",
    "            yes.append(all_npy[sample[b]])\n",
    "            yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "        \n",
    "        for b in range(len(yesr)):\n",
    "            r_3[b]=max(yesr[b])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes = np.array(yes)\n",
    "        \n",
    "        # positive sample\n",
    "        train_t_sample = train_t[z]\n",
    "        for ta in train_t_sample:\n",
    "            #print(ta,'--> positive feedback')\n",
    "            \n",
    "            pos = sample.index(ta)\n",
    "            \n",
    "            image_1=np.expand_dims(all_npy[ta],0)\n",
    "            train_f_sample = random.sample(train_f[z],10)\n",
    "            \n",
    "            for b in train_f_sample:\n",
    "                image_2 = np.expand_dims(all_npy[b],0)\n",
    "                \n",
    "                _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                    [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                    feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                               l_id:sample, l_id_len:[len(sample)],\n",
    "                               positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                               r: r_3, image_i: image_1, image_j: image_2})\n",
    "                \n",
    "                '''Observe all params\n",
    "                print('u,vi,vj',_norm_par[:3])\n",
    "                print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                print('beta',_norm_par[7])\n",
    "                print('Embedding',_norm_par[8])\n",
    "                print('after softmax:', r3)\n",
    "                print('before softmax:', _a_list)\n",
    "                print('---------------------------------------------------')\n",
    "                '''\n",
    "                train_auc += _auc\n",
    "                total_loss += _loss\n",
    "                length += 1\n",
    "    \n",
    "    print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "    print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "    \n",
    "    loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "    \n",
    "    print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "    print('==================================================')\n",
    "    \n",
    "print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "print('End time:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.61395583]]\n",
      "acc= 0.7869769313304721\n",
      "==================================================\n",
      "Iteration: 1\n",
      "loss= [[0.54928829]]\n",
      "acc= 0.8299400929899857\n",
      "==================================================\n",
      "Iteration: 2\n",
      "loss= [[0.52603437]]\n",
      "acc= 0.8485917381974248\n",
      "==================================================\n",
      "Iteration: 3\n",
      "loss= [[0.5095818]]\n",
      "acc= 0.8603183118741059\n",
      "==================================================\n",
      "Iteration: 4\n",
      "loss= [[0.50282592]]\n",
      "acc= 0.8666845493562232\n",
      "==================================================\n",
      "Iteration: 5\n",
      "loss= [[0.4953117]]\n",
      "acc= 0.8738286838340487\n",
      "==================================================\n",
      "Iteration: 6\n",
      "loss= [[0.49440673]]\n",
      "acc= 0.8774320457796853\n",
      "==================================================\n",
      "Iteration: 7\n",
      "loss= [[0.49470889]]\n",
      "acc= 0.8794974964234621\n",
      "==================================================\n",
      "Iteration: 8\n",
      "loss= [[0.49471549]]\n",
      "acc= 0.8816970672389127\n",
      "==================================================\n",
      "Iteration: 9\n",
      "loss= [[0.48999219]]\n",
      "acc= 0.8855776108726753\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 11)\n",
      "[0.6139558325509656, 0.5492882899119278, 0.5260343668969063, 0.5095818035251252, 0.502825919002593, 0.49531169667605507, 0.4944067347885372, 0.4947088893732117, 0.4947154906004113, 0.48999219029417024]\n",
      "[0.7869769313304721, 0.8299400929899857, 0.8485917381974248, 0.8603183118741059, 0.8666845493562232, 0.8738286838340487, 0.8774320457796853, 0.8794974964234621, 0.8816970672389127, 0.8855776108726753]\n"
     ]
    }
   ],
   "source": [
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print(epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print(loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhU1ZnH8e9Ls+8KKMquEKWVoNCCBpcoQUFFjJAIiAEBNRm3JGog0ZkQNMZJRqNJjCPdsqooA04GXEAxRuOC0MiiggqytqA2GFkEhKbf+eMUUrQN3dDVfWv5fZ6nn66qe2/VW6X8+tS5555j7o6IiKSvalEXICIilUtBLyKS5hT0IiJpTkEvIpLmFPQiImlOQS8ikuYU9JISzCzLzLabWetE7iuSCUzj6KUymNn2uLt1ga+AvbH717v741VflUhmUtBLpTOzNcBId597iH2qu3tR1VWVmvQ5yZFQ141EwszuNrOnzGyqmW0DhpjZWWY2z8y+MLONZvYnM6sR27+6mbmZtY3dfyy2/Xkz22Zmb5pZu8PdN7a9j5l9aGZbzOzPZva6mQ07SN0HrTG2vZOZzTWzz83sEzP7RVxN/25mH5nZVjPLN7Pjzay9mXmJ13ht3+ub2UgzezX2Op8Dd5pZBzN7OfYam8xsipk1iju+jZn9zcwKY9sfNLPasZo7xu13nJntMLMmR/5fUlKBgl6i9H3gCaAR8BRQBNwCNAV6AL2B6w9x/GDg34GjgXXAXYe7r5kdA0wDbo+97mqg2yGe56A1xsJ2LjALOA74FvCP2HG3AwNi+zcGRgK7DvE68b4DLAeaAf8JGHA30BzIBk6IvTfMrDrwLLASaAu0Aqa5+67Y+xxS4jOZ4+6by1mHpCgFvUTpNXef5e7F7r7T3Re4+1vuXuTuq4BxwHmHOH66u+e7+x7gceC0I9j3UmCxu/9fbNsfgU0He5IyarwMWOfuD7r7V+6+1d3nx7aNBH7l7iti73exu39+6I/na+vc/WF33xv7nD5095fcfbe7fxareV8NZxH+CI1y9y9j+78e2zYJGGxmFrt/NTClnDVICqsedQGS0dbH3zGzk4H7gK6EE7jVgbcOcfwncbd3APWPYN/j4+twdzezgoM9SRk1tgI+Osihh9pWlpKfU3PgT4RvFA0IDbbCuNdZ4+57KcHdXzezIuBsM/sX0JrQ+pc0pxa9RKnkSIBHgHeB9u7eEPgPQjdFZdoItNx3J9babXGI/Q9V43rgxIMcd7BtX8Zet27cY81L7FPyc/pPwiimTrEahpWooY2ZZR2kjsmE7purCV06Xx1kP0kjCnpJJg2ALcCXsZOGh+qfT5RngC5m1jfWv30LoS/8SGqcCbQ2sxvNrJaZNTSzff39ecDdZnaiBaeZ2dGEbxqfEE5GZ5nZdUCbMmpuQPgDscXMWgG3xW17E9gM3GNmdc2sjpn1iNs+hXCuYDAh9CUDKOglmdwKDAW2EVrOT1X2C7r7p8CVwP2EgDwRWERoMR9Wje6+BegF9Ac+BT5kf9/5H4C/AS8BWwl9+7U9jG++FvgV4dxAew7dXQXwa8IJ4y2EPy4z4mooIpx36Eho3a8jBPu+7WuAd4Cv3P2NMl5H0oTG0YvEiXV5bAAGuPs/o66nMpjZZGCVu4+JuhapGjoZKxnPzHoD84CdwC+BPcD8Qx6UoszsBKAf0CnqWqTqqOtGBM4GVhFGrlwEfD8dT1Ka2e+AJcA97r4u6nqk6qjrRkQkzalFLyKS5pKuj75p06betm3bqMsQEUkpCxcu3OTupQ4NTrqgb9u2Lfn5+VGXISKSUsxs7cG2qetGRCTNKehFRNKcgl5EJM0lXR99afbs2UNBQQG7dpV3+m5JtNq1a9OyZUtq1KhR9s4iklRSIugLCgpo0KABbdu2Zf9U2lJV3J3NmzdTUFBAu3btyj5ARJJKSnTd7Nq1iyZNmijkI2JmNGnSRN+oRFJUSgQ9oJCPmD5/kdSVEl03IiLpas8eWLwYXn8dWrSAH/wg8a+hoC+HzZs307NnTwA++eQTsrKyaNYsXIA2f/58atasWeZzXHPNNYwePZqTTjrpoPs89NBDNG7cmKuuuioxhYtI0vnXv2DevBDsr78O8+fDjh1h26BBCvrINGnShMWLFwMwZswY6tevz2233XbAPu6Ou1OtWum9YRMmTCjzdW644YaKFysiScMdVq3aH+qvvw7LloXHs7Lg9NNh5Ejo0SP8tDjUIpYVkDJ99Mlo5cqVZGdnc9VVV3HKKaewceNGrrvuOnJycjjllFMYO3bs1/ueffbZLF68mKKiIho3bszo0aPp3LkzZ511Fp999hkAd955Jw888MDX+48ePZpu3bpx0kkn8cYbYTGgL7/8kv79+5Odnc2AAQPIycn5+o9QvF//+tecccYZnHrqqfz4xz9m3yylH374IRdccAGdO3emS5curFmzBoB77rmHTp060blzZ+64447K/NhE0tbu3fDWW3D//dC/Pxx3HLRvD0OHwlNPQatWMHYs/P3vsGULLFgADz4IP/xh5YU8pGCL/qc/Df1ZiXTaaRDL18P2/vvvM3nyZHJycgC49957OfrooykqKuL8889nwIABZGdnH3DMli1bOO+887j33nv5+c9/zvjx4xk9evQ3ntvdmT9/PjNnzmTs2LHMnj2bP//5zzRv3pwZM2awZMkSunTpUmpdt9xyC7/5zW9wdwYPHszs2bPp06cPgwYNYsyYMfTt25ddu3ZRXFzMrFmzeP7555k/fz516tTh888/P7IPQyTDfP45vPFGaKm/8Ubohtk3OK1dO+jVa39r/ZRT4CBf+CtdygV9sjnxxBO/DnmAqVOn8uijj1JUVMSGDRtYtmzZN4K+Tp069OnTB4CuXbvyz3+WvmLdFVdc8fU++1rer732GqNGjQKgc+fOnHLKKaUe+9JLL/GHP/yBXbt2sWnTJrp27cqZZ57Jpk2b6Nu3LxAuggKYO3cuw4cPp06dOgAcffTRR/JRiKQ1d1i58sBumOXLw7bq1aFLF/jJT0Kof+c7oTWfLFIu6I+05V1Z6tWr9/XtFStW8OCDDzJ//nwaN27MkCFDSh17Hn/yNisri6KiolKfu1atWmXuU5odO3Zw44038vbbb9OiRQvuvPNOjYEXOUxffQULFx7YYo/1stK4cQjzIUNCsJ9xBtStG229h6I++gTaunUrDRo0oGHDhmzcuJE5c+Yk/DV69OjBtGnTAHjnnXdYtmzZN/bZuXMn1apVo2nTpmzbto0ZM2YAcNRRR9GsWTNmzZoFhAvRduzYQa9evRg/fjw7d+4EUNeNZKRNm2DmTBg1Cs4+Gxo1CiF+++3w7rvQpw+MGxdub94Mzz4Lv/oVnHdecoc8pGCLPpl16dKF7OxsTj75ZNq0aUOPHj0S/ho33XQTP/rRj8jOzv76p1GjRgfs06RJE4YOHUp2djbHHXcc3bt3/3rb448/zvXXX88dd9xBzZo1mTFjBpdeeilLliwhJyeHGjVq0LdvX+66666E1y4StT17YN26MBJm9erws2oVLFkCH3wQ9qlRA7p2hRtv3N8Nc+yx0dZdUeVaM9bMegMPAllAnrvfW2J7a2AS0Di2z2h3f87MagB5QBfCH5XJ7v67Q71WTk6Ol1x4ZPny5XTs2LHcbyqdFRUVUVRURO3atVmxYgUXXnghK1asoHr1yv+brf8Okuzc4dNPvxnk+26vXw/Fxfv3r1ED2rSBjh1DoPfoATk5EDtdlVLMbKG755S2rcx0MLMs4CGgF1AALDCzme4e32dwJzDN3R82s2zgOaAt8AOglrt3MrO6wDIzm+ruayr0jjLY9u3b6dmzJ0VFRbg7jzzySJWEvEiy2Lq19BBftQrWrIFYD+TXjjsOTjgBzjknjIQ54YT9v48/PoxnT3flSYhuwEp3XwVgZk8C/YD4oHegYex2I2BD3OP1zKw6UAfYDWxNQN0Zq3HjxixcuDDqMkQqze7doXultCBfvTr0j8dr2DCE9sknh370+CBv0yY1W+eJVp6gbwGsj7tfAHQvsc8Y4AUzuwmoB3wv9vh0wh+FjUBd4Gfu/o0zfWZ2HXAdQOvWrUstwt01sVaEytPFJ1Iee/fCxo2h9b1mzTeDvKDgm90rbduG8O7a9cAgb9cOjjoKFA2Hlqjv/IOAie5+n5mdBUwxs1MJ3wb2AscDRwH/NLO5+74d7OPu44BxEProSz557dq12bx5s6Yqjsi++ej3jbsXOZQ9e0Jf+Nq14WfNmgNvr18PJUcLH398CO1zz90f4JnWvVKZyhP0HwOt4u63jD0WbwTQG8Dd3zSz2kBTYDAw2933AJ+Z2etADrCKw9CyZUsKCgooLCw8nMMkgfatMCWyc2foWiktxNeuhQ0bDmyRm4V+8rZt4cwz4corw+02bfb/VvdK5SpP0C8AOphZO0LADyQEeLx1QE9gopl1BGoDhbHHLyC08OsBZwKHfclTjRo1tLKRSBXZtu3grfG1a8OolnhZWWEOlzZt4IIL9of3viBv1QrKMcGrVKIyg97di8zsRmAOYejkeHd/z8zGAvnuPhO4Fcg1s58RTsAOc3c3s4eACWb2HmDABHdfWmnvRkTKtHt3mEFx9erSA73k9XK1akHr1iG4+/Y9MMTbtAldKxr4ldzKNY6+KpU2jl5Ejow7fPRRmGzrrbfCz6JFIez3qVfvm+Ed3yo/9tjoJuOS8qvQOHoRSR2bN+8P9fnzw8++4Yh164aLgW6+Ofxu3z4EeZMmGrWS7hT0Iilq164wZXd8a/2jj8I2szAt7uWXQ/fu0K1buK8ulsyk/+wiKaC4OEyRuy/Q588PIb9nT9jeokUI82uvDcHetSs0aBBtzZI8FPQiSaiwcH+g7/v9xRdhW716YVrcn/88hHv37pW7OpGkPgW9SMR27gwnSONb66tXh23VqkGnTmHB6O7dw0/HjrqASA6Pgl6kChUXh+lw41vrS5fuv1K0VasQ5j/5yf4umLi1bUSOiIJepAqsXg1//StMmLB/FEyDBqEL5vbb958wTabl5yR9KOhFKklxMcydC3/5CzzzTOiGufxyuOSSEOwnn6zx6VI1FPQiCbZ1K0yaBA89FLppjjkG7rgDrr8eNF2QREFBL5Ig778fWu+TJsH27aErZsqUcCI1ts67SCQU9CIVsHdv6Jb5y19CN03NmjBwINxwQwh6kWSgoBc5Aps3w6OPhhOsa9eGLpnf/hZGjgxdNSLJREEvchgWLQqt9yeeCFMQnHce3Hcf9Oun6QUkeel/TZEy7NkDM2aEgH/99TA52NChoXumU6eoqxMpm4Je5CA++QQeeST8bNwIJ54I998Pw4aFdUpFUoWCXiSOO8ybB3/+M0yfHlrzffpAXh707q1x75KaFPQihPlmnnwydM+8/TY0bBi6Zv7t36BDh6irE6kYBb1ktLVr4eGHQ4t98+YwZ/vDD8OQIVC/ftTViSSGgl4yjju8/HLonpk5MzzWrx/cdBN897tabUnSj4JeMsb27TB5cuieWb4cmjaFUaPgxz8Oi1+LpCsFvaS9RYtg/PgQ8lu3hql/J06EK6+E2rWjrk6k8inoJS0VFoaLmiZMgCVLwtQEAwaE7pnu3dU9I5lFQS9pY88emD07hPszz4T7OTmhq2bQIDj66KgrFImGgl5S3rvvhq6Yxx6DTz8Nc83cfHO4elVXrooo6CVFff45TJ0aAj4/P8wz07dvuGq1Tx+oUSPqCkWSh4JeUsbevfDCCyHc//Y32L0bOneGBx6AwYOhWbOoKxRJTgp6SXoffBDCffJk2LABmjQJQyKHDYPTT4+6OpHkp6CXpLRlCzz1VAj4N9+ErKzQJfOnP8Gll2rFJpHDoaCXpFFcDH//ewj3p58O889kZ8Mf/gBXXQXHHRd1hSKpSUEvkfvoo7DO6qRJsG4dNG4cumWuuSYMj9SYd5GKUdBLJLZvh//5n9B6f/XVEOYXXgi//32Yd0ZXrIokTrlm1zaz3mb2gZmtNLPRpWxvbWYvm9kiM1tqZhfHbfu2mb1pZu+Z2Ttmpn/CGcodXnkltNSbN4fhw8OCHvfcE1rys2drWgKRylBmi97MsoCHgF5AAbDAzGa6+7K43e4Eprn7w2aWDTwHtDWz6sBjwNXuvsTMmgB7Ev4uJKmtXbu/a2bVKmjQIFypes01cNZZ6poRqWzl6brpBqx091UAZvYk0A+ID3oHGsZuNwI2xG5fCCx19yUA7r45EUVLavjss7B4x4wZoTV/wQXwm9/A978P9epFXZ1I5ihP0LcA1sfdLwC6l9hnDPCCmd0E1AO+F3v8W4Cb2RygGfCku/++QhVLSpg1C0aODMMk77gj3G7TJuqqRDJTolbAHARMdPeWwMXAFDOrRvhDcjZwVez3982sZ8mDzew6M8s3s/zCwsIElSRR2L4drrsOLrssDIfMz4e77lLIi0SpPEH/MdAq7n7L2GPxRgDTANz9TaA20JTQ+n/V3Te5+w5C332Xki/g7uPcPcfdc5rpOvaU9cYbYUqCvDwYPRreegtOPTXqqkSkPEG/AOhgZu3MrCYwEJhZYp91QE8AM+tICPpCYA7Qyczqxk7MnseBffuSBnbvDt0z55wTLnp65RX43e909apIsiizj97di8zsRkJoZwHj3f09MxsL5Lv7TOBWINfMfkY4MTvM3R34l5ndT/hj4cBz7v5sZb0ZqXrLloWFtBctCsMl//hHaNiw7ONEpOpYyOPkkZOT4/n5+VGXIWUoLg4LeowaBfXrQ24uXH551FWJZC4zW+juOaVt05WxctgKCsIUBS+9FCYYy8uDY4+NuioROZhEjbqRDDF1ali1ad48GDcOZs5UyIskOwW9lMu//hWuZh08GDp2hMWL4dprdVWrSCpQ0EuZ5s4Nrfjp0+Huu8MkZO3bR12ViJSXgl4OaudOuOUW6NUrzE8zb14YRlldZ3ZEUoqCXkq1cCF06RJWdLr5Znj7bejaNeqqRORIKOjlAEVF8NvfwplnwrZt8OKL8OCDUKdO1JWJyJHSl3D52kcfwdVXhzVaBw6Ev/4Vjjoq6qpEpKLUohfcwwVPnTvD8uXwxBNhGKVCXiQ9qEWf4T79NEwh/Mwz0LMnTJgArVqVfZyIpA616DPY3/4WZpecOxceeABeeEEhL5KOFPQZaNs2GDEirPTUqlUYYXPLLVBN/zeIpCX9084wr70W+uInTgxj4ufNg+zsqKsSkcqkoM8Qu3fDL38J554bpi149dVwlWvNmlFXJiKVTSdjM8C774Y545csCfPT3HdfuNJVRDKDWvRprLg4LASSkwMbN4aZJseNU8iLZBq16NPUxx+Hi59efjks1J2bC8ccE3VVIhIFBX0aKiyE888PrfhHH4VrrtF0wiKZTEGfZrZvh0suCatAzZ0L3/lO1BWJSNQU9Glk924YMCDMNPm//6uQF5FAQZ8miovDRVBz5sD48dC3b9QViUiy0KibNPGLX8Bjj8E994Q+eRGRfRT0aeC//iuMjb/pJhg9OupqRCTZKOhT3JQpcPvt8MMfhonJNLpGREpS0Kew2bNh+PAwvfDkyZqUTERKp2hIUW+9Bf37Q6dO8PTTUKtW1BWJSLJS0KegDz4IY+WbN4fnn4eGDaOuSESSmYI+xWzYABddBFlZYSjlscdGXZGIJDuNo08hX3wBvXvD5s3wyivQvn3UFYlIKlDQp4hdu6BfP3j/fXjuOejSJeqKRCRVKOhTwN69MHhwWCxk6lT43veirkhEUkm5+ujNrLeZfWBmK83sG5fkmFlrM3vZzBaZ2VIzu7iU7dvN7LZEFZ4p3OGGG8LcNQ8+CAMHRl2RiKSaMoPezLKAh4A+QDYwyMxKrjJ6JzDN3U8HBgJ/LbH9fuD5ipebecaOhUceCVe83nxz1NWISCoqT4u+G7DS3Ve5+27gSaBfiX0c2DfIrxGwYd8GM7scWA28V/FyM8t//zeMGRPmrrnnnqirEZFUVZ6gbwGsj7tfEHss3hhgiJkVAM8BNwGYWX1gFPCbCleaYZ5+OnTZXHJJWP5PUxuIyJFK1Dj6QcBEd28JXAxMMbNqhD8Af3T37Yc62MyuM7N8M8svLCxMUEmp65VXwsnXbt1g2jSorlPmIlIB5YmQj4FWcfdbxh6LNwLoDeDub5pZbaAp0B0YYGa/BxoDxWa2y93/En+wu48DxgHk5OT4kbyRdLF0aRhGecIJ8MwzULdu1BWJSKorT9AvADqYWTtCwA8EBpfYZx3QE5hoZh2B2kChu5+zbwczGwNsLxnyst+aNeGCqPr1w1WvTZpEXZGIpIMyg97di8zsRmAOkAWMd/f3zGwskO/uM4FbgVwz+xnhxOwwd8/olvnh2rQpTG2wcye89hq0alX2MSIi5WHJlsc5OTmen58fdRlVavv2MNXw0qVhQe8ePaKuSERSjZktdPec0rbpNF/E9uwJC3rn54eLohTyIpJoCvoIFReHhUPmzIHcXLjssqgrEpF0pGmKIzRqVFjQ++67YeTIqKsRkXSloI/IffeFRb1vuAF+9auoqxGRdKagj8Bjj8Ftt8EPfhAmKtNVryJSmRT0VWzOnDB3zfnnw5QpYaUoEZHKpKCvQgsWhAW9Tz01jLDRgt4iUhUU9FXkww/h4ovhmGPCgt6NGkVdkYhkCgV9FdiwAS68MPTFz5kDzZtHXZGIZBKNo69kW7ZAnz5hioN//AM6dIi6IhHJNAr6SrRvQe/ly+HZZyGn1IuTRUQql4K+kuzdC1ddFeaWf+IJ6NUr6opEJFOpj74SuMONN4ZVov74Rxg0KOqKRCSTKegrwV13hfVeR42Cn/406mpEJNMp6BPsmWfg17+GoUPhd7+LuhoREQV9wv3pT9C6dZiNUlMbiEgyUNAn0OrV8OKLMGIE1KgRdTUiIoGCPoHGj4dq1cJcNiIiyUJBnyBFRSHoe/fWeq8iklwU9Akye3aY6uDaa6OuRETkQAr6BMnNhWOPhUsuiboSEZEDKegTYMOGMMXBNdfoJKyIJB8FfQJMnBimPBgxIupKRES+SUFfQcXF8OijYcWo9u2jrkZE5JsU9BX08suwahWMHBl1JSIipVPQV1BeHhx1FFxxRdSViIiUTkFfAZs2hRkqr74aateOuhoRkdIp6Cvgscdg925124hIclPQHyH3MHa+e3fo1CnqakREDk4rTB2hefNg2bLQRy8ikszUoj9CublQvz5ceWXUlYiIHJqC/ghs3QpPPRWWCKxfP+pqREQOrVxBb2a9zewDM1tpZqNL2d7azF42s0VmttTMLo493svMFprZO7HfFyT6DURh6lTYsUMnYUUkNZTZR29mWcBDQC+gAFhgZjPdfVncbncC09z9YTPLBp4D2gKbgL7uvsHMTgXmAC0S/B6qXF4efPvbcMYZUVciIlK28rTouwEr3X2Vu+8GngT6ldjHgYax242ADQDuvsjdN8Qefw+oY2a1Kl52dBYvhvz80JrXUoEikgrKE/QtgPVx9wv4Zqt8DDDEzAoIrfmbSnme/sDb7v5VyQ1mdp2Z5ZtZfmFhYbkKj0puLtSqBUOGRF2JiEj5JOpk7CBgoru3BC4GppjZ189tZqcA/wlcX9rB7j7O3XPcPadZs2YJKinxduyAxx+HAQPCtAciIqmgPEH/MRC/OF7L2GPxRgDTANz9TaA20BTAzFoC/wv8yN0/qmjBUZo+HbZs0SpSIpJayhP0C4AOZtbOzGoCA4GZJfZZB/QEMLOOhKAvNLPGwLPAaHd/PXFlRyMvDzp0gHPPjboSEZHyKzPo3b0IuJEwYmY5YXTNe2Y21swui+12K3CtmS0BpgLD3N1jx7UH/sPMFsd+jqmUd1LJ3n8f/vlPnYQVkdRjIY+TR05Ojufn50ddxjfcfjs88AAUFIS1YUVEkomZLXT3nNK26crYcti9GyZNgssuU8iLSOpR0JfDzJlQWKgrYUUkNSnoyyE3F1q1ggsvjLoSEZHDp6Avw5o18OKLMHw4ZGVFXY2IyOFT0Jdh/Pjwe/jwaOsQETlSCvpD2Ls3BP1FF0Hr1lFXIyJyZBT0hzB7Nnz8sa6EFZHUpqA/hLw8OOYYuPTSqCsRETlyCvqD2LgRZs2CYcOgZs2oqxEROXIK+oOYNCn00Y8YEXUlIiIVo6AvRXFx6LY57zz41reirkZEpGIU9KV45RX46CNdCSsi6UFBX4rcXGjcGPr3j7oSEZGKU9CXsHkzzJgRlgqsUyfqakREKk5BX8Jjj4XZKjV2XkTShYI+jns4CXvGGfDtb0ddjYhIYijo47z1Frz7rlrzIpJeFPRx8vKgXj0YODDqSkREEkdBH7NtGzz5ZAj5Bg2irkZEJHEU9DFTp8KXX6rbRkTSj4I+Ji8PTj0VunWLuhIRkcRS0ANLlsCCBaE1bxZ1NSIiiaWgJ7Tma9UKF0mJiKSbjA/6nTvDRVL9+8PRR0ddjYhI4mV80M+YAV98oQnMRCR9ZXzQ5+ZC+/bw3e9GXYmISOXI6KD/8EN49dWwuIhOwopIusrooM/Lg6yssFygiEi6ytig3707LBfYty80bx51NSIilSdjg37WLPjsM10JKyLpL2ODPi8PWraEiy6KuhIRkcpVrqA3s95m9oGZrTSz0aVsb21mL5vZIjNbamYXx237Zey4D8wsKWJ17VqYMweGDw999CIi6ax6WTuYWRbwENALKAAWmNlMd18Wt9udwDR3f9jMsoHngLax2wOBU4Djgblm9i1335voN3I4JkwIv4cPj7IKEZGqUZ4WfTdgpbuvcvfdwJNAvxL7ONAwdrsRsCF2ux/wpLt/5e6rgZWx54vM3r0wfjxceCG0aRNlJSIiVaM8Qd8CWB93vyD2WLwxwBAzKyC05m86jGMxs+vMLN/M8gsLC8tZ+pF54QVYv15XwopI5kjUydhBwER3bwlcDEwxs3I/t7uPc/ccd89p1qxZgkoqXW4uNGsGl11WqS8jIpI0yhPGHwOt4u63jD0WbwQwDcDd3wRqA03LeWyV+eSTMKxy6FCoWTOqKkREqlZ5gn4B0MHM2plZTcLJ1Zkl9lkH9AQws46EoC+M7TfQzGqZWTugAzA/UcUfrkmToKhI3TYiklnKHHXj7kVmdiMwB8gCxrv7e4yiY2AAAAToSURBVGY2Fsh395nArUCumf2McGJ2mLs78J6ZTQOWAUXADVGNuHEPY+fPOQdOOimKCkREomEhj5NHTk6O5+fnJ/x5//EPOP98mDwZrr464U8vIhIpM1vo7jmlbcuYK2Pz8qBRo7DAiIhIJsmIoP/8c5g+PSwVWLdu1NWIiFStjAj6xx+Hr77SSVgRyUxpH/TuYex8Tg6cdlrU1YiIVL20D/r58+Gdd9SaF5HMlfZBn5cX+uUHDYq6EhGRaKR10G/bBlOnwpVXQsOGZe8vIpKO0jron3oKvvxSq0iJSGZL66DPzYXsbDjzzKgrERGJTtoG/dKl4UTstdeCWdTViIhEJ22DPi8vzFA5ZEjUlYiIRCstg37nTpgyBa64Apo2jboaEZFopWXQP/00fPGFxs6LiECaBn1eHpxwQpitUkQk06Vd0K9YEaYkHjECqqXduxMROXxpF4WPPgpZWTBsWNSViIgkh7QK+j17YOJEuOQSOP74qKsREUkOaRX0zzwDn36qK2FFROKlVdDn5oaWfO/eUVciIpI80ibo16+H2bNh+HCoXuaS5yIimSNtgn77drj44hD0IiKyX9q0fTt2DH30IiJyoLRp0YuISOkU9CIiaU5BLyKS5hT0IiJpTkEvIpLmFPQiImlOQS8ikuYU9CIiac7cPeoaDmBmhcDaqOuooKbApqiLSCL6PA6kz2M/fRYHqsjn0cbdm5W2IemCPh2YWb6750RdR7LQ53EgfR776bM4UGV9Huq6ERFJcwp6EZE0p6CvHOOiLiDJ6PM4kD6P/fRZHKhSPg/10YuIpDm16EVE0pyCXkQkzSnoE8jMWpnZy2a2zMzeM7Nboq4pamaWZWaLzCzjl4Uxs8ZmNt3M3jez5WZ2VtQ1RcnMfhb7d/KumU01s9pR11SVzGy8mX1mZu/GPXa0mb1oZitiv49KxGsp6BOrCLjV3bOBM4EbzCw74pqidguwPOoiksSDwGx3PxnoTAZ/LmbWArgZyHH3U4EsYGC0VVW5iUDvEo+NBl5y9w7AS7H7FaagTyB33+jub8dubyP8Q24RbVXRMbOWwCVAXtS1RM3MGgHnAo8CuPtud/8i2qoiVx2oY2bVgbrAhojrqVLu/irweYmH+wGTYrcnAZcn4rUU9JXEzNoCpwNvRVtJpB4AfgEUR11IEmgHFAITYl1ZeWZWL+qiouLuHwP/BawDNgJb3P2FaKtKCse6+8bY7U+AYxPxpAr6SmBm9YEZwE/dfWvU9UTBzC4FPnP3hVHXkiSqA12Ah939dOBLEvS1PBXF+p77Ef4AHg/UM7Mh0VaVXDyMfU/I+HcFfYKZWQ1CyD/u7k9HXU+EegCXmdka4EngAjN7LNqSIlUAFLj7vm940wnBn6m+B6x290J33wM8DXwn4pqSwadmdhxA7PdniXhSBX0CmZkR+mCXu/v9UdcTJXf/pbu3dPe2hJNsf3f3jG2xufsnwHozOyn2UE9gWYQlRW0dcKaZ1Y39u+lJBp+cjjMTGBq7PRT4v0Q8qYI+sXoAVxNar4tjPxdHXZQkjZuAx81sKXAacE/E9UQm9s1mOvA28A4hizJqOgQzmwq8CZxkZgVmNgK4F+hlZisI33ruTchraQoEEZH0pha9iEiaU9CLiKQ5Bb2ISJpT0IuIpDkFvYhImlPQi4ikOQW9iEia+38g9ICD/aYVzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1582, 128)\n",
      "photo latent shape:  (165, 128)\n",
      "Auxilary latent shape:  (165, 128)\n",
      "Embedding shape: (200, 4882)\n",
      "Wu weight shape: (1582, 165, 128)\n",
      "Wy weight shape: (1582, 165, 128)\n",
      "Wa weight shape: (1582, 165, 128)\n",
      "Wv weight shape: (1582, 165, 200)\n",
      "Beta shape: (1582, 200)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Wu weight shape:', Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez('./weight/' + SAVE_NAME + '.npz', \n",
    "         U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reload params if crash\n",
    "# SAVE_NAME = 'MRM_ALL_Embedding200_L2_resplit'\n",
    "\n",
    "# params = np.load('./weight/' + SAVE_NAME + '.npz')\n",
    "# print(params)\n",
    "# U = params['U']\n",
    "# Y = params['Y']\n",
    "# A = params['A']\n",
    "# E = params['E']\n",
    "# Au = params['Wu']\n",
    "# Ay = params['Wy']\n",
    "# Aa = params['Wa']\n",
    "# Av = params['Wv']\n",
    "# B = params['B']\n",
    "\n",
    "# print('User latent shape: ',U.shape)\n",
    "# print('photo latent shape: ', Y.shape)\n",
    "# print('Auxilary latent shape: ',A.shape)\n",
    "# print('Embedding shape:', E.shape)\n",
    "# print('Wu weight shape:', Au.shape)\n",
    "# print('Wy weight shape:', Ay.shape)\n",
    "# print('Wa weight shape:', Aa.shape)\n",
    "# print('Wv weight shape:', Av.shape)\n",
    "# print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13\n",
      "alpha:         0.0011270478776924516\n",
      "==================================================\n",
      "1 51\n",
      "alpha:         0.0028572341274367293\n",
      "==================================================\n",
      "2 54\n",
      "alpha:         0.005317226724119608\n",
      "==================================================\n",
      "3 61\n",
      "alpha:         0.006329731028474432\n",
      "==================================================\n",
      "4 65\n",
      "alpha:         0.007446460909719815\n",
      "==================================================\n",
      "5 88\n",
      "alpha:         0.008037432246321792\n",
      "==================================================\n",
      "6 93\n",
      "alpha:         0.009408025736073104\n",
      "==================================================\n",
      "7 96\n",
      "alpha:         0.010086980621737454\n",
      "==================================================\n",
      "8 114\n",
      "alpha:         0.012041382887974869\n",
      "==================================================\n",
      "9 130\n",
      "alpha:         0.012041382887974869\n",
      "==================================================\n",
      "10 135\n",
      "alpha:         0.022152984834239345\n",
      "==================================================\n",
      "11 142\n",
      "alpha:         0.02352250374595661\n",
      "==================================================\n",
      "12 146\n",
      "alpha:         0.027720729619207865\n",
      "==================================================\n",
      "13 161\n",
      "alpha:         0.03272402978759986\n",
      "==================================================\n",
      "14 163\n",
      "alpha:         0.03441651503240954\n",
      "==================================================\n",
      "15 178\n",
      "alpha:         0.038107981625850766\n",
      "==================================================\n",
      "16 186\n",
      "alpha:         0.040185428141203815\n",
      "==================================================\n",
      "17 189\n",
      "alpha:         0.04139747462085822\n",
      "==================================================\n",
      "18 191\n",
      "alpha:         0.055738033804788686\n",
      "==================================================\n",
      "19 198\n",
      "alpha:         0.061814401383037544\n",
      "==================================================\n",
      "20 206\n",
      "alpha:         0.06193611322865598\n",
      "==================================================\n",
      "21 209\n",
      "alpha:         0.06456726169212249\n",
      "==================================================\n",
      "22 224\n",
      "alpha:         0.0720590590073923\n",
      "==================================================\n",
      "23 228\n",
      "alpha:         0.07573488693468301\n",
      "==================================================\n",
      "24 255\n",
      "alpha:         0.07689801663633646\n",
      "==================================================\n",
      "25 283\n",
      "alpha:         0.07785259064553085\n",
      "==================================================\n",
      "26 285\n",
      "alpha:         0.07846542835946257\n",
      "==================================================\n",
      "27 292\n",
      "alpha:         0.08139437139473174\n",
      "==================================================\n",
      "28 313\n",
      "alpha:         0.08373515669543055\n",
      "==================================================\n",
      "29 318\n",
      "alpha:         0.08406081651678624\n",
      "==================================================\n",
      "30 326\n",
      "alpha:         0.08844542550389246\n",
      "==================================================\n",
      "31 327\n",
      "alpha:         0.08869988869728535\n",
      "==================================================\n",
      "32 333\n",
      "alpha:         0.0926770451963588\n",
      "==================================================\n",
      "33 334\n",
      "alpha:         0.09694535277215757\n",
      "==================================================\n",
      "34 350\n",
      "alpha:         0.09867639566943073\n",
      "==================================================\n",
      "35 393\n",
      "alpha:         0.09876290765016982\n",
      "==================================================\n",
      "36 407\n",
      "alpha:         0.11084163603334528\n",
      "==================================================\n",
      "37 429\n",
      "alpha:         0.11620064297387694\n",
      "==================================================\n",
      "38 432\n",
      "alpha:         0.1200935792810886\n",
      "==================================================\n",
      "39 435\n",
      "alpha:         0.12352841477759025\n",
      "==================================================\n",
      "40 440\n",
      "alpha:         0.12371029968256418\n",
      "==================================================\n",
      "41 447\n",
      "alpha:         0.12400044479833729\n",
      "==================================================\n",
      "42 449\n",
      "alpha:         0.12401910047136852\n",
      "==================================================\n",
      "43 451\n",
      "alpha:         0.12402424800566983\n",
      "==================================================\n",
      "44 457\n",
      "alpha:         0.13010183159242328\n",
      "==================================================\n",
      "45 466\n",
      "alpha:         0.13091655802619784\n",
      "==================================================\n",
      "46 469\n",
      "alpha:         0.13177366629501866\n",
      "==================================================\n",
      "47 476\n",
      "alpha:         0.13369051905060605\n",
      "==================================================\n",
      "48 501\n",
      "alpha:         0.13745907425052228\n",
      "==================================================\n",
      "49 505\n",
      "alpha:         0.13798037703755375\n",
      "==================================================\n",
      "50 514\n",
      "alpha:         0.14098522322905846\n",
      "==================================================\n",
      "51 538\n",
      "alpha:         0.14241806948886726\n",
      "==================================================\n",
      "52 541\n",
      "alpha:         0.142456136111276\n",
      "==================================================\n",
      "53 542\n",
      "alpha:         0.1440263613188958\n",
      "==================================================\n",
      "54 546\n",
      "alpha:         0.14532007571258027\n",
      "==================================================\n",
      "55 548\n",
      "alpha:         0.14777020119004583\n",
      "==================================================\n",
      "56 552\n",
      "alpha:         0.15455337648746892\n",
      "==================================================\n",
      "57 563\n",
      "alpha:         0.15783084862256797\n",
      "==================================================\n",
      "58 569\n",
      "alpha:         0.158271378546131\n",
      "==================================================\n",
      "59 592\n",
      "alpha:         0.1594461374979537\n",
      "==================================================\n",
      "60 600\n",
      "alpha:         0.1645935291161335\n",
      "==================================================\n",
      "61 644\n",
      "alpha:         0.1708493378097961\n",
      "==================================================\n",
      "62 646\n",
      "alpha:         0.17093130440676424\n",
      "==================================================\n",
      "63 664\n",
      "alpha:         0.17104859606926592\n",
      "==================================================\n",
      "64 689\n",
      "alpha:         0.17121524547832448\n",
      "==================================================\n",
      "65 696\n",
      "alpha:         0.17277831476499791\n",
      "==================================================\n",
      "66 704\n",
      "alpha:         0.1730920666180212\n",
      "==================================================\n",
      "67 727\n",
      "alpha:         0.18353303636873178\n",
      "==================================================\n",
      "68 735\n",
      "alpha:         0.1895026718568971\n",
      "==================================================\n",
      "69 740\n",
      "alpha:         0.19361518146841555\n",
      "==================================================\n",
      "70 741\n",
      "alpha:         0.19361518146841555\n",
      "==================================================\n",
      "71 747\n",
      "alpha:         0.19441634432894822\n",
      "==================================================\n",
      "72 758\n",
      "alpha:         0.19476003581196433\n",
      "==================================================\n",
      "73 775\n",
      "alpha:         0.2018556726939402\n",
      "==================================================\n",
      "74 777\n",
      "alpha:         0.20273325434629857\n",
      "==================================================\n",
      "75 778\n",
      "alpha:         0.20892211853077797\n",
      "==================================================\n",
      "76 781\n",
      "alpha:         0.21297170287921646\n",
      "==================================================\n",
      "77 788\n",
      "alpha:         0.21592951171318836\n",
      "==================================================\n",
      "78 810\n",
      "alpha:         0.22343665085913986\n",
      "==================================================\n",
      "79 817\n",
      "alpha:         0.22367087581374234\n",
      "==================================================\n",
      "80 821\n",
      "alpha:         0.22702294285474897\n",
      "==================================================\n",
      "81 859\n",
      "alpha:         0.2371207782989887\n",
      "==================================================\n",
      "82 864\n",
      "alpha:         0.24049242457520273\n",
      "==================================================\n",
      "83 865\n",
      "alpha:         0.24358820205084225\n",
      "==================================================\n",
      "84 877\n",
      "alpha:         0.2458557563856092\n",
      "==================================================\n",
      "85 919\n",
      "alpha:         0.246507780712548\n",
      "==================================================\n",
      "86 928\n",
      "alpha:         0.2496450909688018\n",
      "==================================================\n",
      "87 939\n",
      "alpha:         0.25228555510600315\n",
      "==================================================\n",
      "88 940\n",
      "alpha:         0.2570330364653799\n",
      "==================================================\n",
      "89 946\n",
      "alpha:         0.2577454781167096\n",
      "==================================================\n",
      "90 958\n",
      "alpha:         0.2594044065224245\n",
      "==================================================\n",
      "91 1010\n",
      "alpha:         0.2644430682724892\n",
      "==================================================\n",
      "92 1022\n",
      "alpha:         0.2654516920543345\n",
      "==================================================\n",
      "93 1034\n",
      "alpha:         0.26658288286460113\n",
      "==================================================\n",
      "94 1043\n",
      "alpha:         0.2679581406445535\n",
      "==================================================\n",
      "95 1083\n",
      "alpha:         0.26893368398668327\n",
      "==================================================\n",
      "96 1093\n",
      "alpha:         0.2735755697591083\n",
      "==================================================\n",
      "97 1098\n",
      "alpha:         0.27476253890640767\n",
      "==================================================\n",
      "98 1103\n",
      "alpha:         0.2794900899776634\n",
      "==================================================\n",
      "99 1116\n",
      "alpha:         0.28009714068411373\n",
      "==================================================\n",
      "100 1130\n",
      "alpha:         0.2874417051578616\n",
      "==================================================\n",
      "101 1133\n",
      "alpha:         0.2890612914032577\n",
      "==================================================\n",
      "102 1140\n",
      "alpha:         0.2915916972533117\n",
      "==================================================\n",
      "103 1149\n",
      "alpha:         0.2957951537396382\n",
      "==================================================\n",
      "104 1161\n",
      "alpha:         0.2974931895937176\n",
      "==================================================\n",
      "105 1182\n",
      "alpha:         0.29772072300700847\n",
      "==================================================\n",
      "106 1195\n",
      "alpha:         0.299886793243205\n",
      "==================================================\n",
      "107 1197\n",
      "alpha:         0.3074226719952065\n",
      "==================================================\n",
      "108 1206\n",
      "alpha:         0.3079117221226007\n",
      "==================================================\n",
      "109 1209\n",
      "alpha:         0.3089088872157732\n",
      "==================================================\n",
      "110 1220\n",
      "alpha:         0.3090941596574936\n",
      "==================================================\n",
      "111 1221\n",
      "alpha:         0.31129838353852635\n",
      "==================================================\n",
      "112 1232\n",
      "alpha:         0.3144711820958615\n",
      "==================================================\n",
      "113 1236\n",
      "alpha:         0.3145310592438998\n",
      "==================================================\n",
      "114 1247\n",
      "alpha:         0.3287793417488656\n",
      "==================================================\n",
      "115 1266\n",
      "alpha:         0.33333544424204736\n",
      "==================================================\n",
      "116 1285\n",
      "alpha:         0.34161922136746614\n",
      "==================================================\n",
      "117 1287\n",
      "alpha:         0.3445278890772304\n",
      "==================================================\n",
      "118 1300\n",
      "alpha:         0.3488395297834495\n",
      "==================================================\n",
      "119 1301\n",
      "alpha:         0.348967580537898\n",
      "==================================================\n",
      "120 1309\n",
      "alpha:         0.35197886780009274\n",
      "==================================================\n",
      "121 1310\n",
      "alpha:         0.353370033764241\n",
      "==================================================\n",
      "122 1316\n",
      "alpha:         0.3583644652381917\n",
      "==================================================\n",
      "123 1327\n",
      "alpha:         0.3611990901268496\n",
      "==================================================\n",
      "124 1330\n",
      "alpha:         0.3646542213449143\n",
      "==================================================\n",
      "125 1342\n",
      "alpha:         0.3648486218523243\n",
      "==================================================\n",
      "126 1354\n",
      "alpha:         0.3648781736301713\n",
      "==================================================\n",
      "127 1372\n",
      "alpha:         0.36658737616958825\n",
      "==================================================\n",
      "128 1385\n",
      "alpha:         0.37154672513919634\n",
      "==================================================\n",
      "129 1393\n",
      "alpha:         0.37428765124492275\n",
      "==================================================\n",
      "130 1399\n",
      "alpha:         0.37890606071533445\n",
      "==================================================\n",
      "131 1402\n",
      "alpha:         0.37940856182249755\n",
      "==================================================\n",
      "132 1409\n",
      "alpha:         0.38172450552723486\n",
      "==================================================\n",
      "133 1429\n",
      "alpha:         0.38389642556506437\n",
      "==================================================\n",
      "134 1436\n",
      "alpha:         0.3846959920651337\n",
      "==================================================\n",
      "135 1437\n",
      "alpha:         0.38557717083608545\n",
      "==================================================\n",
      "136 1442\n",
      "alpha:         0.3873315852132968\n",
      "==================================================\n",
      "137 1466\n",
      "alpha:         0.3907827172695082\n",
      "==================================================\n",
      "138 1470\n",
      "alpha:         0.3922708804514385\n",
      "==================================================\n",
      "139 1493\n",
      "alpha:         0.4037592134376297\n",
      "==================================================\n",
      "140 1494\n",
      "alpha:         0.4056444085111392\n",
      "==================================================\n",
      "141 1508\n",
      "alpha:         0.40613197842915955\n",
      "==================================================\n",
      "142 1516\n",
      "alpha:         0.40731788508842287\n",
      "==================================================\n",
      "143 1518\n",
      "alpha:         0.40776156022029325\n",
      "==================================================\n",
      "144 1525\n",
      "alpha:         0.4084539211795942\n",
      "==================================================\n",
      "145 1529\n",
      "alpha:         0.4084539211795942\n",
      "==================================================\n",
      "146 1547\n",
      "alpha:         0.40864580786442906\n",
      "==================================================\n",
      "147 1554\n",
      "alpha:         0.41196535729177536\n",
      "==================================================\n",
      "148 1563\n",
      "alpha:         0.4140903405624659\n",
      "==================================================\n",
      "149 1573\n",
      "alpha:         0.4167017914123838\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "'''\n",
    "\n",
    "#with Embedding\n",
    "result = np.zeros((usr_test_amount, movie_nb))\n",
    "RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "#test_idx --> Test 的 index length = 150\n",
    "sum_alpha = 0\n",
    "test_yes_id = []\n",
    "\n",
    "for s in range(usr_test_amount):\n",
    "    print(s, test_idx[s])\n",
    "\n",
    "    yes = []\n",
    "    sample = train_t[test_idx[s]]\n",
    "    alpha = np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "        \n",
    "# #         ''' Observe each part in attention\n",
    "#         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "#         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "#         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "#         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "#         print('The sum of each par -->',\n",
    "#               '\\nw1:',testW1,\n",
    "#               '\\nWuU:',WuUu,\n",
    "#               '\\nwyY:',WyYy,\n",
    "#               '\\nWaA:',WaAa,\n",
    "#               '\\nWvV:',WvVy)\n",
    "# #         '''\n",
    "\n",
    "        alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n",
    "                   np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                   np.dot(Aa[test_idx[s]][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                   np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "        \n",
    "        \n",
    "        # relu part\n",
    "        alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "        # tanh part\n",
    "#         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "        \n",
    "    mul = np.zeros((1,latent_dim))\n",
    "    added_alpha = np.add(alpha,0.0000000001)\n",
    "    norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "    sum_alpha += np.sum(alpha)\n",
    "    \n",
    "    print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "    print('==================================================')\n",
    "    \n",
    "    for i in range(len(sample)):\n",
    "        mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "    new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "    for k in range(movie_nb):\n",
    "        result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 165)\n"
     ]
    }
   ],
   "source": [
    "#取出test的資料\n",
    "print(RS.shape)\n",
    "\n",
    "testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "        \n",
    "for z in range(usr_test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    # positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    # not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "#     print(user_id)\n",
    "#     print(youtube_t)\n",
    "#     print(youtube_f)\n",
    "    \n",
    "    #前面放target的RS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "        \n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "    \n",
    "#     print(testRS[z])\n",
    "#     print(target[z])\n",
    "#     print('==============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 32) (150, 32)\n",
      "num of positive data in testing: 1078.0\n"
     ]
    }
   ],
   "source": [
    "print(target.shape, testRS.shape)\n",
    "sumtarget = np.sum(target)\n",
    "print('num of positive data in testing:', sumtarget) # whole matrix: 4800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 32)\n"
     ]
    }
   ],
   "source": [
    "all_sort = []\n",
    "\n",
    "for i in range(usr_test_amount):\n",
    "    all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "    \n",
    "all_sort = np.asarray(all_sort)\n",
    "print(all_sort.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1\n",
      "Num of TP: 66\n",
      "prec: 0.44\n",
      "recall: 0.061224489795918366\n",
      "F1_score: 0.10749185667752442\n",
      "*****\n",
      "Top 3\n",
      "Num of TP: 268\n",
      "prec: 0.5955555555555555\n",
      "recall: 0.24860853432282004\n",
      "F1_score: 0.35078534031413616\n",
      "*****\n",
      "Top 5\n",
      "Num of TP: 586\n",
      "prec: 0.7813333333333333\n",
      "recall: 0.5435992578849722\n",
      "F1_score: 0.6411378555798688\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "NDCG@ 1\n",
      "NDCG score: 0.44\n",
      "*****\n",
      "NDCG@ 3\n",
      "NDCG score: 0.4470762836530299\n",
      "*****\n",
      "NDCG@ 5\n",
      "NDCG score: 0.43052447907042\n",
      "*****\n",
      "NDCG@ 10\n",
      "NDCG score: 0.4883964447616151\n",
      "*****\n",
      "NDCG@ 15\n",
      "NDCG score: 0.5589241986945467\n",
      "*****\n",
      "NDCG@ 20\n",
      "NDCG score: 0.6150928103323983\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "MAP: 0.4544465516672971\n"
     ]
    }
   ],
   "source": [
    "# Top N\n",
    "N = [1, 3, 5]\n",
    "correct = 0\n",
    "\n",
    "for n in N:\n",
    "    print('Top', n)\n",
    "    \n",
    "    for i in range(len(testRS)):\n",
    "        topn = topN(testRS[i], n)\n",
    "        sum_target = int(np.sum(target[i]))\n",
    "        \n",
    "        TP = 0\n",
    "        for i in topn:\n",
    "            if i < sum_target:\n",
    "                TP += 1\n",
    "                \n",
    "        correct += TP\n",
    "\n",
    "    print('Num of TP:', correct)\n",
    "\n",
    "    prec = correct/(len(testRS)*n)\n",
    "    recall = correct/sumtarget\n",
    "    \n",
    "    print('prec:', prec)\n",
    "    print('recall:', recall)\n",
    "    print('F1_score:', F1_score(prec, recall))\n",
    "    \n",
    "    print('*****')\n",
    "\n",
    "print('\\n==============================\\n')\n",
    "\n",
    "# NDCG\n",
    "num_ndcgs = [1, 3, 5, 10, 15, 20]\n",
    "for num_ndcg in num_ndcgs:\n",
    "    print('NDCG@', num_ndcg)\n",
    "    print('NDCG score:', NDCG(target, testRS, num_ndcg))\n",
    "    print('*****')\n",
    "\n",
    "print('\\n==============================\\n')\n",
    "\n",
    "# MAP\n",
    "print('MAP:', MAP(target,testRS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
